<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>ross &#8211; sawberries</title>
	<atom:link href="http://localhost/sawberries/author/ross/feed/?simply_static_page=50245" rel="self" type="application/rss+xml" />
	<link>https://www.sawberries.com</link>
	<description>part of www.sawberry.com sites</description>
	<lastBuildDate>Sun, 28 Apr 2024 03:42:42 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.2</generator>

<image>
	<url>https://www.sawberries.com/wp-content/uploads/2024/04/cropped-DALL·E-2024-04-26-12.21.04-A-512x512-favicon-design-that-incorporates-a-playful-twist-on-the-concept-of-a-strawberry-symbolizing-connections-between-people.-The-strawberry-shou-32x32.webp</url>
	<title>ross &#8211; sawberries</title>
	<link>https://www.sawberries.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Screen Graphics 64(1983)(Abacus)</title>
		<link>https://www.sawberries.com/2024/04/28/d64__screen_graphics_64_ita/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sun, 28 Apr 2024 03:42:42 +0000</pubDate>
				<category><![CDATA[retrotech]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/28/d64__screen_graphics_64_ita/</guid>

					<description><![CDATA[Screen Graphics 64 Screen Graphics 64 is an extension software written by Roy Wainwright of Abacus Software. It adds 24 graphics commands to Commodore 64 BASIC. These include switching to high resolution and multicolour screens, sprite manipulation tools, and commands for drawing pixels, lines, boxe&#8230;. This item belongs to: software/softwarelibrary_c64_applications. This item has files of [&#8230;]]]></description>
										<content:encoded><![CDATA[<div><img decoding="async" width="160" style="padding-right:3px;float:left;" src="https://archive.org/services/get-item-image.php?identifier=d64__Screen_Graphics_64_ita&amp;mediatype=software&amp;collection=softwarelibrary_c64_applications"></p>
<p>Screen Graphics 64 Screen Graphics 64 is an extension software written by Roy Wainwright of Abacus Software. It adds 24 graphics commands to Commodore 64 BASIC. These include switching to high resolution and multicolour screens, sprite manipulation tools, and commands for drawing pixels, lines, boxe&#8230;.</p>
<p>This item belongs to: software/softwarelibrary_c64_applications.</p>
<p>This item has files of the following types: Archive BitTorrent, Emulator Screenshot, Item Tile, JPEG Thumb, Metadata, PNG, Unknown</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Ms. Pac-Man(1984)(Atarisoft)[cr bibi][DOCS]</title>
		<link>https://www.sawberries.com/2024/04/28/d64__ms_pac_man_cr_bibi_docs/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sun, 28 Apr 2024 03:42:41 +0000</pubDate>
				<category><![CDATA[retrotech]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/28/d64__ms_pac_man_cr_bibi_docs/</guid>

					<description><![CDATA[Ms. Pac-Man(1984)(Atarisoft) Also For Windows, PC Booter, Game Boy, Xbox, SNES, Genesis, Lynx, NES, Game Gear, SEGA Master System, Atari 2600, Apple II, Atari 5200, Atari 7800, Atari 8-bit, ZX Spectrum, VIC-20, TI-99/4A, Palm OS, Xbox 360, iPod Classic, iPhone, BlackBerry, Android, PlayStation 4, Xb&#8230;. This item belongs to: software/softwarelibrary_c64_cracks. This item has files of [&#8230;]]]></description>
										<content:encoded><![CDATA[<div><img decoding="async" width="160" style="padding-right:3px;float:left;" src="https://archive.org/services/get-item-image.php?identifier=d64__ms_pac_man_cr_bibi_docs&amp;mediatype=software&amp;collection=softwarelibrary_c64_cracks"></p>
<p>Ms. Pac-Man(1984)(Atarisoft) Also For Windows, PC Booter, Game Boy, Xbox, SNES, Genesis, Lynx, NES, Game Gear, SEGA Master System, Atari 2600, Apple II, Atari 5200, Atari 7800, Atari 8-bit, ZX Spectrum, VIC-20, TI-99/4A, Palm OS, Xbox 360, iPod Classic, iPhone, BlackBerry, Android, PlayStation 4, Xb&#8230;.</p>
<p>This item belongs to: software/softwarelibrary_c64_cracks.</p>
<p>This item has files of the following types: Archive BitTorrent, Emulator Screenshot, Item Tile, JPEG Thumb, Metadata, PNG, Unknown</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>H.E.R.O.(1984)(Activision)[cr 2703]</title>
		<link>https://www.sawberries.com/2024/04/28/d64__h_e_r_o_cr_2703/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sun, 28 Apr 2024 03:42:40 +0000</pubDate>
				<category><![CDATA[retrotech]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/28/d64__h_e_r_o_cr_2703/</guid>

					<description><![CDATA[H.E.R.O.(1984)(Activision, Inc.) Also For Windows, Atari 2600, ColecoVision, Apple II, Atari 5200, Atari 8-bit, ZX Spectrum, MSX, Xbox 360, SG-1000 Released 1984 Published By Activision, Inc. Developed By Activision, Inc&#8230;. This item belongs to: software/softwarelibrary_c64_cracks. This item has files of the following types: Archive BitTorrent, Emulator Screenshot, Item Tile, JPEG Thumb, Metadata, PNG, Unknown]]></description>
										<content:encoded><![CDATA[<div><img decoding="async" width="160" style="padding-right:3px;float:left;" src="https://archive.org/services/get-item-image.php?identifier=d64__h_e_r_o_cr_2703&amp;mediatype=software&amp;collection=softwarelibrary_c64_cracks"></p>
<p>H.E.R.O.(1984)(Activision, Inc.) Also For Windows, Atari 2600, ColecoVision, Apple II, Atari 5200, Atari 8-bit, ZX Spectrum, MSX, Xbox 360, SG-1000 Released 1984 Published By Activision, Inc. Developed By Activision, Inc&#8230;.</p>
<p>This item belongs to: software/softwarelibrary_c64_cracks.</p>
<p>This item has files of the following types: Archive BitTorrent, Emulator Screenshot, Item Tile, JPEG Thumb, Metadata, PNG, Unknown</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>The Burden: A Darkly Funny Musical Punctures Existential Dread with Unusually Cheerful Song and Dance</title>
		<link>https://www.sawberries.com/2024/04/28/the-burden-short-film/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sun, 28 Apr 2024 03:38:32 +0000</pubDate>
				<category><![CDATA[Animation]]></category>
		<category><![CDATA[art]]></category>
		<category><![CDATA[humor]]></category>
		<category><![CDATA[Niki Lindroth von Bahr]]></category>
		<category><![CDATA[short film]]></category>
		<category><![CDATA[video]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/28/the-burden-short-film/</guid>

					<description><![CDATA[﻿ Today we’re returning to a dark comedy classic that, although released in 2017, rings just as true in 2024. Directed by Swedish animator Niki Lindroth von Bahr, “The Burden” is a wildly wry musical that skewers loneliness, greed, beauty myths, and the existential woes of modern life through a lively cast of animal characters. [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/O_Mmd26EN9g?si=ENSfZ5wZknVY6Lv2" width="960" height="540" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span></iframe></p>
<p>Today we’re returning to a dark comedy classic that, although released in 2017, rings just as true in 2024. Directed by Swedish animator <a href="http://www.nikilindroth.com/" target="_blank" rel="noopener">Niki Lindroth von Bahr</a>, “<a href="https://www.youtube.com/watch?v=O_Mmd26EN9g&amp;t=327s" target="_blank" rel="noopener">The Burden</a>” is a wildly wry musical that skewers loneliness, greed, beauty myths, and the existential woes of modern life through a lively cast of animal characters.</p>
<p>The award-winning short film visits a bleak supermarket, hotel, call center, and fast-food restaurant where employees break into song and dance, sometimes to the tune of common sales refrains. “Would you like to sign up for our money-back guarantee? Try our satisfaction guarantee?” monkeys croon. When an apocalypse hits the bizarrely relatable world, the characters jump at the chance for change.</p>
<p>Watch “The Burden” above, and find Lindroth von Bahr’s other films on <a href="https://vimeo.com/user2928324" target="_blank" rel="noopener">Vimeo</a>.</p>
<p> </p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-246099 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-2.gif" alt='an animated gif of three monkeys who work at a call center singing "say that you are sorry, do apologize, but never cancel the agreement"' width="800" height="335"></p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-246101 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-1.jpg" alt="a fish in a bathroom and another in sweats open their hotel room doors to the lobby where another fish stands behind the desk" width="2000" height="989" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-1.jpg 2000w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-1-640x316.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-1-960x475.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-1-1536x760.jpg 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-246100 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-3.gif" alt="a fish working at a hotel says &quot;this is where you come if you want to stay for a very long time. if you are alone, or if you dont have anyone, or if you dont want to be with anyone, or if you can't be with anyone, or if nobody wants to be with you.&quot;" width="800" height="335"></p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-246102 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-2.jpg" alt="a dog moves his cart to stock the shelves at a grocery store" width="2000" height="921" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-2.jpg 2000w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-2-640x295.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-2-960x442.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-2-1536x707.jpg 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-246098 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/burden-1.gif" alt="two mice dance with their cleaning supplies in a restaurant" width="800" height="335"></p>
<p>Do stories and artists like this matter to you? Become a <a href="https://www.thisiscolossal.com/members">Colossal Member</a> today and support independent arts publishing for as little as $5 per month. The article <a href="https://www.thisiscolossal.com/2024/04/the-burden-short-film/">The Burden: A Darkly Funny Musical Punctures Existential Dread with Unusually Cheerful Song and Dance</a> appeared first on <a href="https://www.thisiscolossal.com/">Colossal</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How to Transition your Career from Non Tech Field to Generative AI?</title>
		<link>https://www.sawberries.com/2024/04/28/transition-your-career-from-non-tech-field-to-generative-ai/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sun, 28 Apr 2024 03:38:27 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Beginner]]></category>
		<category><![CDATA[Career]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Large Language Models]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Python]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/28/transition-your-career-from-non-tech-field-to-generative-ai/</guid>

					<description><![CDATA[Introduction In today’s rapidly evolving world, the term ‘Generative AI’ is on everyone’s lips. Studies reveal that Generative AI is becoming indispensable in the workplace, with the market projected to reach $1.3 trillion by 2032. If you’ve been considering a career transition from a non-tech field to Generative AI, now is the time! This article explores the [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction In today’s rapidly evolving world, the term ‘Generative AI’ is on everyone’s lips. Studies reveal that Generative AI is becoming indispensable in the workplace, with the market projected to reach $1.3 trillion by 2032. If you’ve been considering a career transition from a non-tech field to Generative AI, now is the time! This article explores the […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/transition-your-career-from-non-tech-field-to-generative-ai/">How to Transition your Career from Non Tech Field to Generative AI?</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Understanding SoTA Language Models (BERT, RoBERTA, ALBERT, ELECTRA)</title>
		<link>https://www.sawberries.com/2024/04/27/understanding-state-of-art-language-html/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 10:50:09 +0000</pubDate>
				<category><![CDATA[natural language nlu deep learning bert albert roberta]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/understanding-state-of-art-language-html/</guid>

					<description><![CDATA[ Hi everyone, There are a ton of language models out there today! Many of which have their unique way of learning &#8220;self-supervised&#8221; language representations that can be used by other downstream tasks.  In this article, I decided to summarize the current trends and share some key insights to glue all these novel approaches together.  😃 [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p> Hi everyone,</p>
<p>There are a ton of language models out there today! Many of which have their unique way of learning &#8220;self-supervised&#8221; language representations that can be used by other downstream tasks. </p>
<p>In this article, I decided to summarize the current trends and share some key insights to glue all these novel approaches together.  <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f603.png" alt="😃" class="wp-smiley" style="height: 1em; max-height: 1em;" /> (Slide credits: Delvin et. al. Stanford CS224n)</p>
<p></p>
</p>
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijQBnFFCwJXTfqeZE77irx4Gv9gfKmroLr-cMb6xmQkASkUhPtIG0FoEl8phTt2TSwBKvhtjRFr2Fvom2hXZ6vYRLDYB8cBbMV8kOepKpyWMY76vMJbvof0gOZ6ovdc8VtFQYm2GtbdQST/" style="margin-left: 1em; margin-right: 1em;"><img fetchpriority="high" decoding="async" alt="" data-original-height="787" data-original-width="1400" height="255" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijQBnFFCwJXTfqeZE77irx4Gv9gfKmroLr-cMb6xmQkASkUhPtIG0FoEl8phTt2TSwBKvhtjRFr2Fvom2hXZ6vYRLDYB8cBbMV8kOepKpyWMY76vMJbvof0gOZ6ovdc8VtFQYm2GtbdQST/w453-h255/image.png" width="453"></a></div>
</p>
<p><span></span><span><a name="more"></a></span></p>
<p></p>
<p><b><span style="font-size: medium;">Problem: Context-free/Atomic Word Representations</span></b></p>
<p>We started with context-free approaches like <span style="color: #2b00fe;"><b>word2vec, GloVE embeddings </b><a href="http://ankit-ai.blogspot.com/2019/01/a-summary-of-natural-language-models.html">in my previous post</a></span>. The drawback of these approaches is that they do not account for syntactic context. e.g. &#8220;open a <b>bank</b> account&#8221; v/s &#8220;on the river <b>bank</b>&#8220;. The word <b>bank </b>has different meanings depending on the context the word is used in.</p>
</p>
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiTAmZ14tnFvFbZfzQydZ8YCfcEyrb1NRyQs8Wkf-pXf-m-gpBCTQ5W8cX_RtAbhyuQnJpHlVZsGDYF6ziZv5u-Pn63Z5xtv1IAvV0pKTQf6uzoEVTHclW32sgXoB8N6zzelSLGF8NGWhU3/" style="margin-left: 1em; margin-right: 1em;"><img decoding="async" alt="" data-original-height="1104" data-original-width="2048" height="187" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiTAmZ14tnFvFbZfzQydZ8YCfcEyrb1NRyQs8Wkf-pXf-m-gpBCTQ5W8cX_RtAbhyuQnJpHlVZsGDYF6ziZv5u-Pn63Z5xtv1IAvV0pKTQf6uzoEVTHclW32sgXoB8N6zzelSLGF8NGWhU3/w346-h187/image.png" width="346"></a></div>
<p><b><span style="font-size: medium;">Solution #1: Contextual Word Representations</span></b></p>
<p>With <span style="color: #2b00fe;"><b>ELMo</b></span> the community started building forward (left to right) and backward (right to left) sequence language models, and used embeddings extracted from both (concatenated) these models as pre-trained embeddings for downstream modeling tasks like classification (Sentiment etc.)</p>
</p>
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgK_mgZY6p1kHIg8RXjrqxbJh_BagP93GhnAG3vNS0d45qS1a6z9yGnomHajyJo-rk3q1oQzUCv2vCNVPA0edPZMQ8_jdoggj_sQCXgtRHgyq_v1QOwJ6NfpRe1LfqUoGIpbCXfvq3GYDSK/" style="margin-left: 1em; margin-right: 1em;"><img decoding="async" alt="" data-original-height="1097" data-original-width="2048" height="171" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgK_mgZY6p1kHIg8RXjrqxbJh_BagP93GhnAG3vNS0d45qS1a6z9yGnomHajyJo-rk3q1oQzUCv2vCNVPA0edPZMQ8_jdoggj_sQCXgtRHgyq_v1QOwJ6NfpRe1LfqUoGIpbCXfvq3GYDSK/" width="320"></a></div>
<div class="separator" style="clear: both; text-align: center;"></div>
<p><b>Potential drawback:</b></p>
<p>ELMo can be considered a &#8220;weakly bi-directional model&#8221; as they trained 2 separate models here.</p>
<p><span style="font-size: medium;"><b>Solution #2: Truly bi-directional Contextual Representations</b></span></p>
</p>
<div class="separator" style="clear: both; text-align: justify;">To solve the drawback of &#8220;weakly bi-directional&#8221; approach and the information bottleneck that comes with LSTMs / Recurrent approaches &#8211; the Transformer architecture was developed. Transformers unlike LSTM/RNN are an entirely feedforward network. Here is a quick summary of the architecture:</div>
<div class="separator" style="clear: both; font-size: large; font-weight: bold; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiIn8_ApbVr3EjKhApGY7mhoFYYQ2_-hM-pgHoIUG8j15iP8EAWgfgvdQ5z9q7tOXye7uNwy2-6K7aQEo9CTQZHiQPRW0EibRde4gWIAx54FdJEtIhClV4rH3INi9RjlxeEjfCsZ1SGr7rt/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1078" data-original-width="2048" height="168" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiIn8_ApbVr3EjKhApGY7mhoFYYQ2_-hM-pgHoIUG8j15iP8EAWgfgvdQ5z9q7tOXye7uNwy2-6K7aQEo9CTQZHiQPRW0EibRde4gWIAx54FdJEtIhClV4rH3INi9RjlxeEjfCsZ1SGr7rt/" width="320"></a></div>
<div class="separator" style="clear: both; text-align: center;"><i><span style="font-size: x-small;"><b>Tip:</b> If you are new to transformers but are familiar with vanilla Multi-Layer Perceptron (MLP) or Fully connected Neural networks. You can think of transformers as being similar to MLP/standard NN with fancy bells and whistles on top of that.</span></i></div>
<div class="separator" style="clear: both; font-weight: bold; text-align: center;"><i><span style="font-size: x-small;"><br /></span></i></div>
<div class="separator" style="clear: both; font-weight: bold; text-align: center;">But, what makes the transformer so much more effective?</div>
<div class="separator" style="clear: both; font-weight: bold; text-align: center;"><i><span style="font-size: x-small;"><br /></span></i></div>
<div class="separator" style="clear: both; text-align: center;">
<div class="separator" style="clear: both; font-size: small; font-style: italic; font-weight: bold; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZ7EXeAdwPAlV2Zu2ZI3hV19CnDUBZXE7TjVCb61511OnHARjrnvv6VKaIT2b_uLzOybBb-Q3_F0M9nAbg9CUKMxgromdcqdhEwdcDJuQEJhB6jDtEqWXW897HxIouq8tnLSUF50YP0F5x/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1116" data-original-width="2048" height="174" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZ7EXeAdwPAlV2Zu2ZI3hV19CnDUBZXE7TjVCb61511OnHARjrnvv6VKaIT2b_uLzOybBb-Q3_F0M9nAbg9CUKMxgromdcqdhEwdcDJuQEJhB6jDtEqWXW897HxIouq8tnLSUF50YP0F5x/" width="320"></a></div>
<div class="separator" style="clear: both; font-size: small; font-style: italic; font-weight: bold; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;"><span style="font-size: medium;"><b>2 key ideas:</b></span></div>
<div class="separator" style="clear: both; text-align: center;"><span style="font-size: medium;"><br /></span></div>
<div class="separator" style="clear: both; text-align: left;">1. <b>Every word has an opportunity to learn a representation with-respect-to every other word (Truly bi-directional)</b> in the sentence (think of every word as a feature given as input to a fully connected network). To further build on this idea let&#8217;s consider the transformer as a fully connected network with 1 hidden layer as shown below:</div>
<div class="separator" style="clear: both; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;">
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVMSOusz3EymtlcMa-gzBotjNwRbcazKzYtHFUMCPmnvuhUQe-t3zwutc1C2LcsfyzquzLDEJ6JllB89Z-vVWaVH3jGP7I74qUGHtNmfr1e7C5TWtddmXj2Dask2s47vjYvGYWhyphenhyphen05MdBX/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="400" data-original-width="600" height="213" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVMSOusz3EymtlcMa-gzBotjNwRbcazKzYtHFUMCPmnvuhUQe-t3zwutc1C2LcsfyzquzLDEJ6JllB89Z-vVWaVH3jGP7I74qUGHtNmfr1e7C5TWtddmXj2Dask2s47vjYvGYWhyphenhyphen05MdBX/" width="320"></a></div>
<div class="separator" style="clear: both; text-align: center;">source: <a href="https://stackoverflow.com/questions/65528631/what-exactly-contains-the-word-vector-of-word2vec-or-generally-of-word-embeddin">Stackoverflow</a></div>
<div class="separator" style="clear: both; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;">If x1 and x5 are 2 words/tokens from my earlier example (<b>on</b> the river <b>bank</b>), now x1 has access to x5 regardless of the distance between x1 and x5 (the word <b>on </b>can learn a representation depending on the context provided by the word <b>bank)</b></div>
<div class="separator" style="clear: both; text-align: center;"><b><br /></b></div>
<div class="separator" style="clear: both; text-align: left;">2. Essentially, since every layer can be represented as a <b>big matrix multiplication (parallel computation)</b> over one multiplication per token that happens in an LSTM, <b>the transformer is much faster than an LSTM.</b></div>
<div class="separator" style="clear: both; text-align: left;"><b><br /></b></div>
<div class="separator" style="clear: both; text-align: left;"><span><span id="more-143"></span></span><b><br /></b></div>
<div class="separator" style="clear: both; text-align: center;"></div>
<p><b></p>
<div style="text-align: justify;"><b><span style="font-size: medium;">Problem with bi-directional models:</span></b></div>
<p></b></p>
<div style="text-align: justify;"></div>
</div>
<div class="separator" style="clear: both; font-style: italic; font-weight: bold; text-align: center;">But, Language models (LM) are supposed to model P(w_t+1/w_1..w_t)? How does the model learn anything if you expose all the words to it?</div>
<div class="separator" style="clear: both; font-style: italic; font-weight: bold; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;"><b><span style="color: #2b00fe; font-size: large;">BERT</span></b> develops upon this idea using transformers to learn Masked Language Modeling (MLM) and translates the task to P(w_masked/w_1..w-t)</div>
<div class="separator" style="clear: both; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;">Tradeoff: In MLM, you could be masking and predicting ~15% words in the sentence. However, in Left-to-Right LM you are predicting 100% of words in the sentence (higher sample efficiency).</div>
<div class="separator" style="clear: both; font-size: small; font-style: italic; font-weight: bold; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;">
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxkLb7AL_yHS_aAQdSWYSO2ki04zwVTQAIfcS6RdSIXDV1WGC4DriJZNfSxNb_H5QGoeMjWf8xLyzRVy7hibA8bhzY8fpAHdctDeUXFWRfmnn4jofcPTxH4c8cLMlaLNPReltgIZow-AL2/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1121" data-original-width="2048" height="175" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxkLb7AL_yHS_aAQdSWYSO2ki04zwVTQAIfcS6RdSIXDV1WGC4DriJZNfSxNb_H5QGoeMjWf8xLyzRVy7hibA8bhzY8fpAHdctDeUXFWRfmnn4jofcPTxH4c8cLMlaLNPReltgIZow-AL2/" width="320"></a></div>
<div class="separator" style="clear: both; font-size: small; font-style: italic; font-weight: bold; text-align: center;"></div>
<p>There are some changes in the input to the model with respect to the previous LSTM based approach. The input now has 3 embeddings: </p></div>
<div class="separator" style="clear: both; text-align: center;"></p>
<div class="separator" style="clear: both; font-size: small; font-style: italic; font-weight: bold; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiY_NjTlJRI1GA2roz7xv5dZWHyiqFYdpXM4o72j0m5ozgwzc6erQ1lymKAh_LD8iumKjcMWDxSPhYnH0NJMcM3_pHB04Y1j0cW_bwG3Qn3szcLTgM765OzPG1syMy31Cd_Rtc3eBjlOnsW/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="762" data-original-width="1506" height="162" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiY_NjTlJRI1GA2roz7xv5dZWHyiqFYdpXM4o72j0m5ozgwzc6erQ1lymKAh_LD8iumKjcMWDxSPhYnH0NJMcM3_pHB04Y1j0cW_bwG3Qn3szcLTgM765OzPG1syMy31Cd_Rtc3eBjlOnsW/" width="320"></a></div>
<div class="separator" style="clear: both; font-size: small; font-style: italic; font-weight: bold; text-align: center;"></div>
</div>
<div class="separator" style="clear: both; text-align: justify;"><b>1. Token embeddings</b> &#8211; (Same as embeddings fed into the LSTM model) </div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;"><b>2. Segment Embeddings</b> &#8211; </div>
<div class="separator" style="clear: both; text-align: justify;">
<ul>
<li>Simply tells the model what sentence does this token belongs to e.g. &#8220;<b>Sentence A:</b> The man went to buy milk. <b>Sentence B:</b> The store was closed&#8221;.</li>
</ul>
</div>
<div class="separator" style="clear: both; text-align: justify;"><b>3. Position Embeddings &#8211;</b> </div>
<div class="separator" style="clear: both; text-align: justify;">
<ul>
<li>Can be thought as a token number e.g. The &#8211; 0, man &#8211; 1 and so on.</li>
<p><span></span></ul>
<div></div>
<p><span><!--more--></span></p>
<div></div>
<div>Important to note:</div>
<div></div>
<div><b style="background-color: #fcff01;"></b></div>
<blockquote>
<div><b style="background-color: #fcff01;">BERT is a huge model (110M parameters ~1 GB filesize). Alright, How do we do better?</b></div>
<div></div>
</blockquote>
<div><b style="background-color: #fcff01;"><br /></b></div>
<div><span style="background-color: white;">Studies have shown that <b>overly parameterized models</b> are effective in learning language nuances <b>better</b>. This can be demonstrated by the graph below:</span></div>
<div></div>
<div>
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3E-Z_CfOduhixn0MVdKZyKJS05n-SYKI3XmH7FQuuNs6Bms0QI85jgeNGQHMRPzh7EpavIf5yABx5FSbb8i6L9703NGyWDBxpyKrWqY1VhyY3FxY05WJ7JUNBO-UKQR40duut8us-y1mK/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1175" data-original-width="2048" height="200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3E-Z_CfOduhixn0MVdKZyKJS05n-SYKI3XmH7FQuuNs6Bms0QI85jgeNGQHMRPzh7EpavIf5yABx5FSbb8i6L9703NGyWDBxpyKrWqY1VhyY3FxY05WJ7JUNBO-UKQR40duut8us-y1mK/w348-h200/image.png" width="348"></a></div>
<div class="separator" style="clear: both; text-align: center;"><i>The graph affirms<b></p>
<blockquote><p>&#8220;Bigger the LM, the better it is&#8221;</p></blockquote>
<p></b></i></p>
</p>
</div>
<div class="separator" style="clear: both; text-align: justify;">This is going to be some of our motivation as we look into advancements over the BERT model &#8211;</div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;">We will look into 4 models that have fundamentally improved upon the ideas we introduced for the BERT model.</div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;"><b><span style="color: #2b00fe; font-size: medium;">1. RoBERTA</span></b></div>
<div class="separator" style="clear: both; text-align: justify;">
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0kWMQBKn-AB0ewxR2ZTkn-t2gyvAsNTXEpTKwzJZyJd1ytmMhSAst75mZnSQfB9KVbLt-4DleLiwvDFf41On0VomDI0i2GelCSIgXw3U5KrWLuv6AtQ_QqnCvVAGe6eQPoA33L0ZelpmK/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1127" data-original-width="2048" height="176" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0kWMQBKn-AB0ewxR2ZTkn-t2gyvAsNTXEpTKwzJZyJd1ytmMhSAst75mZnSQfB9KVbLt-4DleLiwvDFf41On0VomDI0i2GelCSIgXw3U5KrWLuv6AtQ_QqnCvVAGe6eQPoA33L0ZelpmK/" width="320"></a></div>
<p><span style="font-size: medium;">The central idea was to train the same BERT model for longer (more epochs) and on more data. The evaluation results show that it does better than the standard BERT model we saw earlier.</span></div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;"><b><span style="color: #2b00fe; font-size: medium;">2. XLNet</span></b></div>
<div class="separator" style="clear: both; text-align: justify;"><span style="font-size: medium;"></p>
<div class="separator" style="clear: both; color: #2b00fe; font-weight: bold; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZsKJG2HUTgom2OoJQmFR0VB8zEpnOyybAAc2GdKxoEx9UnGeLZeVk_Rzt9R7BfutMzRRje-7iVvdJHfgsf8EFW_x2QwXQhyphenhyphenwawGx-n9zcFJMJ1_I8JZdtD4YOduGJoDea22aq3TMGBHii/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1101" data-original-width="2048" height="172" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZsKJG2HUTgom2OoJQmFR0VB8zEpnOyybAAc2GdKxoEx9UnGeLZeVk_Rzt9R7BfutMzRRje-7iVvdJHfgsf8EFW_x2QwXQhyphenhyphenwawGx-n9zcFJMJ1_I8JZdtD4YOduGJoDea22aq3TMGBHii/" width="320"></a></div>
<p>XLNet introduced this idea of relative position embeddings instead of static position embeddings that we saw earlier. These start out as linear relationships and are combined together in deeper layers to learn a non-linear attention function.</span></div>
<div class="separator" style="clear: both; text-align: justify;"><span style="font-size: medium;"><br /></span></div>
<div class="separator" style="clear: both; text-align: justify;"><span style="font-size: medium;"></p>
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVvVPppYdlowluLinjiV5numYQLrAHIvTYJYrt3dgoljHc_6Nq8p7RP1cOB0B3G1vq6-RdD2jSY5MA9X8aWxcB3IFRPwf-TJQknNHW43l6BZvhWZ0RS-d8dJCl7J03DALdi8R0w1cMkS35/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1122" data-original-width="2048" height="175" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVvVPppYdlowluLinjiV5numYQLrAHIvTYJYrt3dgoljHc_6Nq8p7RP1cOB0B3G1vq6-RdD2jSY5MA9X8aWxcB3IFRPwf-TJQknNHW43l6BZvhWZ0RS-d8dJCl7J03DALdi8R0w1cMkS35/" width="320"></a></div>
<p>Additionally, instead of going just Left-to-Right, XLNet introduced this idea of Permutation Language Modelling (PLM) which allows us to randomly permute the order for every training sentence as shown in the figure. You are still predicting one &#8220;MASKED&#8221; word at a time given some permutation of the input. This gives us a much better sample efficiency.</span></div>
<div class="separator" style="clear: both; text-align: justify;"><span style="font-size: medium;"><br /></span></div>
<div class="separator" style="clear: both; text-align: justify;"><span style="font-size: medium;"></p>
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTHqpg77Uwc3zHCyHQzq-YifzeStolUPrGGE8k1mndJjsNGPu_uhdajhBCknpnpBzpXQzWPhHzLJQRE5lpsvbUoNo1vEJ94Oy6cKgaGO3ZL3tauZhWdX4qhTVMiAzzDvMdOeOEwor-LL46/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1111" data-original-width="2048" height="174" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTHqpg77Uwc3zHCyHQzq-YifzeStolUPrGGE8k1mndJjsNGPu_uhdajhBCknpnpBzpXQzWPhHzLJQRE5lpsvbUoNo1vEJ94Oy6cKgaGO3ZL3tauZhWdX4qhTVMiAzzDvMdOeOEwor-LL46/" width="320"></a></div>
<p></span></div>
<div class="separator" style="clear: both; text-align: left;"><b style="text-align: justify;"><span style="color: #2b00fe; font-size: medium;">3. ALBERT</span></b></div>
<div class="separator" style="clear: both; text-align: left;"><span style="text-align: justify;"><span style="font-size: medium;"></p>
<div class="separator" style="clear: both; color: #2b00fe; font-weight: bold; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCI_6bKhOBgikzmqLhYfKewLuptboThFg9gIOPQeuu_bSsHKldvDQZWHZQmnWO1wUaPouEBawkVVPFs84TUmofFb3ECudg2Al7-2azJq4Xhlqvg-z1CPNCcXaZ04SELyyrD8SQjUQkK49T/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1119" data-original-width="2048" height="175" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCI_6bKhOBgikzmqLhYfKewLuptboThFg9gIOPQeuu_bSsHKldvDQZWHZQmnWO1wUaPouEBawkVVPFs84TUmofFb3ECudg2Al7-2azJq4Xhlqvg-z1CPNCcXaZ04SELyyrD8SQjUQkK49T/" width="320"></a></div>
<div class="separator" style="clear: both; text-align: justify;">The idea here was to reduce overfitting by factorizing the input embedding layer. As an example, if the vocab size is 100k and the hidden size is <b>1024</b>. The model could have a hard time generalizing directly in this <b>high dimensional vector space</b> especially for rare words. Instead, ALBERT proposes a factorization technique which first learns a fairly small hidden dimension (128) per word and then learns to a separate function to project this to the transformers hidden dimension of 1024. </div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;">
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglI0HTnjqmOZIqOK1CVW1CjntQC-R1Spu5t8FuCiuk12DEOPtnfRMktEZhncWdB9ULI1oWrGGT9ZxUtIdE8mYMdJt_gdnj_Jmt0YgzzNPBER4TtbC0Id4KAdE5eQky8Ut-3tH9pMkNGPDP/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1102" data-original-width="2048" height="172" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglI0HTnjqmOZIqOK1CVW1CjntQC-R1Spu5t8FuCiuk12DEOPtnfRMktEZhncWdB9ULI1oWrGGT9ZxUtIdE8mYMdJt_gdnj_Jmt0YgzzNPBER4TtbC0Id4KAdE5eQky8Ut-3tH9pMkNGPDP/" width="320"></a></div>
<p></div>
<div class="separator" style="clear: both; text-align: justify;">To further reduce the number of parameters, ALBERT proposes to share all parameters between the transformers layers termed <b>Cross-layer parameter sharing </b>(All 12 layers of BERT share the same parameters). This comes at a cost of speed while training as shown in the table.</div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;"><b><span style="color: #2b00fe;">4. ELECTRA</span></b></div>
<div class="separator" style="clear: both; text-align: justify;"></div>
<div class="separator" style="clear: both; text-align: justify;">
<div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbn1KcOwJpgWJJD_dr_GsR0v51DmLDUH9OSAriQ_MEcZpry09qRqbeB_6tGHXTbQzx-c9pLVridyQ2fYp4jvAm32qTC-2-4a1XrccBAHc3py7hdClejrhBi-AtI4_YHhkbURk-7b_I_c2F/" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" alt="" data-original-height="1140" data-original-width="2048" height="178" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbn1KcOwJpgWJJD_dr_GsR0v51DmLDUH9OSAriQ_MEcZpry09qRqbeB_6tGHXTbQzx-c9pLVridyQ2fYp4jvAm32qTC-2-4a1XrccBAHc3py7hdClejrhBi-AtI4_YHhkbURk-7b_I_c2F/" width="320"></a></div>
<div class="separator" style="clear: both; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: justify;">ELECTRA introduces the idea of using a discriminator to be able to evaluate the quality of the generative language model. This helps the language model (generator) learn better language representations to help misguide the discriminator as an optimization objective.</div>
<div class="separator" style="clear: both; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;"></div>
<div class="separator" style="clear: both; text-align: center;">I hope you enjoyed this post! Stay tuned for more. <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/270c.png" alt="✌" class="wp-smiley" style="height: 1em; max-height: 1em;" /></div>
<div class="separator" style="clear: both; text-align: center;"></div>
</div>
<p></span></span></div>
</div>
</div>
</div>
<p><span><!--more--></span></p>
<p></p>
<p>Slide credits &#8211; Jacob Delvin, Google Language AI</p>
<p><iframe loading="lazy" title="Stanford CS224N: NLP with Deep Learning | Winter 2020 | BERT and Other Pre-trained Language Models" width="500" height="281" src="https://www.youtube.com/embed/knTc-NQSjKA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Your Questions, My Answers on Stanford&#8217;s Graduate AI Certification</title>
		<link>https://www.sawberries.com/2024/04/27/your-questions-my-answers-on-stanfords-html/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 10:50:09 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/your-questions-my-answers-on-stanfords-html/</guid>

					<description><![CDATA[I have been asked a lot of questions lately about Stanford&#8217;s online course offerings and why somebody would choose them over myriad of options online. This is my attempt to bundle them together to help a broader audience. 1. How do you choose classes? It depends on your goals and interests. Here are some questions [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<div dir="ltr" style="text-align: left;" trbidi="on">
I have been asked a lot of questions lately about Stanford&#8217;s online course offerings and why somebody would choose them over myriad of options online. This is my attempt to bundle them together to help a broader audience.</p>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqHT7qNHZOFu8JMcl8Je66UX2tmvKEx-wjA60yaxXFDjZrm8C3UHwfUhGyuVKDrkl5WsVysj_lKyqLJiBIfdw5NJAY1f_9KYz7tE3lEVeFj4uEUJMNk3VqbebWkKwYGfgQSw6vxXm9Jjr1/s1600/how-design-thinking-transforming-learning-experience-free-ebook.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" border="0" data-original-height="460" data-original-width="820" height="179" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqHT7qNHZOFu8JMcl8Je66UX2tmvKEx-wjA60yaxXFDjZrm8C3UHwfUhGyuVKDrkl5WsVysj_lKyqLJiBIfdw5NJAY1f_9KYz7tE3lEVeFj4uEUJMNk3VqbebWkKwYGfgQSw6vxXm9Jjr1/s320/how-design-thinking-transforming-learning-experience-free-ebook.jpg" width="320"></a></div>
<p><b>1. How do you choose classes?</b><br />
It depends on your goals and interests. Here are some questions to ask.</p>
<ul style="text-align: left;">
<li>Goal: </li>
<ul>
<li>What do you want to achieve out of a particular course? </li>
<li>Are you learning for fun or do you want to apply the knowledge to build something?</li>
<li>Do you want to extend/switch careers to become a Deep Learning practitioner?</li>
<li>Do you think these tools will help you solve a real-life problem?</li>
</ul>
<li>Interests:</li>
<ul>
<li>Read through the course page, find out the topics they cover and search for applications/projects related to it. Do these topics interest you? Here is <a href="http://ankit-ai.blogspot.com/2019/11/my-review-of-stanfords-online.html">my review</a> on some of the classes to help you get started.</li>
</ul>
</ul>
<p><b>2. Reference Materials for classes?</b></p>
<ul style="text-align: left;">
<li>Most classes at Stanford are self-contained but you are welcomed to read and research resources, there is tons of literature on most topics as it&#8217;s an active field of research. </li>
<li>Teaching staff usually provides references for each topic which help you consolidate concepts.</li>
</ul>
<p><b>3. Are there any forums to discuss doubts? Is there any form of Mentorship provided?</b></p>
<ul style="text-align: left;">
<li>There are Course Assistants for every class and there is also a forum setup per class where you can discuss doubts and ask questions to help solidify your understanding. </li>
<li>You are also assigned a Mentor for your project which is one of the course assistants for the class. They help give feedback and suggestions to help you navigate and sketch out scope of a project.</li>
</ul>
<div>
<b>4. What can you get out of a class project?</b></div>
<p></p>
<ul style="text-align: left;">
<li>A class project can be an open research problem, your attempt at reproducing ideas presented in a paper or simply applying fundamentals to a real-life problem. This is one of the most interesting parts of the courses which helps you exercise what you have learnt and even explore beyond the class. </li>
<li>Choosing challenging course projects helps you explore and become better at applying concepts and figure out how to use these tools in real-life problems.</li>
</ul>
<p><b>5. What Programming Language is preferred?</b></p>
<ul style="text-align: left;">
<li>Most classes require you to code in Python. </li>
</ul>
<p><b>6. Why is it still worth taking the course when you have online courses at a much lower cost?</b></p>
<ul style="text-align: left;">
<li>These are actual &#8220;Graduate&#8221; courses taken by students at Stanford. I have found them to be quite challenging but at the same time rewarding in ways that broaden your horizon and knowledge with State-of-the-Art (SoTA) literature and techniques. </li>
<li>I would suggest using other online courses as basics to build upon with these Graduate level classes. </li>
</ul>
<p><b><br /></b><br />
<b>7. Why one shouldn&#8217;t one be </b><b>judgmental</b><b> about this course since it is a &#8220;Graduate Certificate&#8221; unlike a full time Master&#8217;s course?</b></p>
<ul style="text-align: left;">
<li>Graduate level courses are more abstract compared to their undergraduate counterparts. Again, It depends on what your goals are, if you have a Master&#8217;s you can update yourself with these classes. </li>
<li>On the other hand, my understanding is that the same courses can be taken as part of an online Master&#8217;s program.</li>
</ul>
<p></p>
<style type="text/css">
p.p1 {margin: 0.0px 0.0px 8.0px 0.0px; font: 11.0px 'Trebuchet MS'; color: #000000; -webkit-text-stroke: #000000}
p.p2 {margin: 0.0px 0.0px 8.0px 0.0px; font: 11.0px 'Trebuchet MS'; color: #000000; -webkit-text-stroke: #000000; min-height: 12.0px}
li.li1 {margin: 0.0px 0.0px 8.0px 0.0px; font: 11.0px 'Trebuchet MS'; color: #000000; -webkit-text-stroke: #000000}
span.s1 {font-kerning: none}
ol.ol1 {list-style-type: decimal}
</style>
</div>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Review : Stanford&#8217;s Online Artificial Intelligence Courses &#8211; Deep Learning and Machine Learning</title>
		<link>https://www.sawberries.com/2024/04/27/my-review-of-stanfords-online-html/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 10:50:08 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/my-review-of-stanfords-online-html/</guid>

					<description><![CDATA[Hello! I have been enrolled at Stanford and have been taking their courses online. Here are my few cents on the ones I have taken so far. CS224n &#8211; Natural Language Processing with Deep Learning (Prof. Manning) Difficulty: 4/5 (Moderate) What to expect:  Get exposed to State-of-the-Art (SoTA) Deep Learning techniques applied to NLP. Key [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<div dir="ltr" style="text-align: left;" trbidi="on">
Hello!</p>
<p><br class="Apple-interchange-newline"><br />
I have been enrolled at Stanford and have been taking their courses online. Here are my few cents on the ones I have taken so far.</p>
<p></p>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuNCqmnTvdcf3q9mGkS3vKFj3vQf8psViEXJQYWnibxD9D9XhmykQdcwaWanB9pNygYIikjF3tsFpvJYtPjmfvy-jOb385-f2DAyCRsZevD5LsU3vJDMVAfgnvrC3De-iAY01EOY87Djd-/s1600/ai-and-dev.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img loading="lazy" decoding="async" border="0" data-original-height="808" data-original-width="1440" height="223" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuNCqmnTvdcf3q9mGkS3vKFj3vQf8psViEXJQYWnibxD9D9XhmykQdcwaWanB9pNygYIikjF3tsFpvJYtPjmfvy-jOb385-f2DAyCRsZevD5LsU3vJDMVAfgnvrC3De-iAY01EOY87Djd-/s400/ai-and-dev.jpg" width="400"></a></div>
<p><b>CS224n &#8211; Natural Language Processing with Deep Learning (Prof. Manning)</b></p>
<ul style="text-align: left;">
<li>Difficulty: 4/5 (Moderate)</li>
<li>What to expect: </li>
<ul>
<li>Get exposed to State-of-the-Art (SoTA) Deep Learning techniques applied to NLP. Key topics: </li>
<ul>
<li>Question and Answering</li>
<li>Text Summarization</li>
<li>Parts of Speech tagging</li>
<li>Sequence-to-Sequence models</li>
<li>Transformers</li>
</ul>
<li>Gives you a very good overview of where NLP is headed, <a href="https://github.com/ankit-ai/cs224n-natural-language-processing-winter2019">homeworks</a> are challenging but allow you to implement latest neural architectures to solve various language problems.</li>
</ul>
<li>My class project: <a href="https://github.com/ankit-ai/BertQA-Attention-on-Steroids">BertQA</a> (99* stars on github) &#8211; Won Best Project Award in the class</li>
</ul>
<div>
</div>
<p><b>CS231n &#8211; Convolutional Neural Networks for Visual Recognition (Prof. Li and Justin Johnson)</b></p>
<div>
</p>
<ul style="text-align: left;">
<li>Difficulty: 4/5 (Moderate)</li>
<li>What to expect: </li>
<ul>
<li>Extensive overview of latest trends in Computer Vision techniques across different domains and applications &#8211; </li>
<ul>
<li>Discriminative models</li>
<li>Unsupervised techniques</li>
<li>Neural Architecture layers and intutions </li>
<li>Segmentation</li>
<li>Generative Techniques</li>
<li>Style Transfer</li>
</ul>
<li>Homeworks are the best part of the class which allow you to implement a variety of Neural Layers and get in-depth intuition of how deep learning actually works.</li>
<li>I would suggest some familiarity with <i>matrix calculus and probability</i> for this course.</li>
</ul>
<li>My class project: <a href="https://github.com/masoudML/Spatio_Temporal_Adversarial_Video_Super_Resolution">Spatio-Temporal Adversarial Video Super Resolution</a></li>
</ul>
<div>
<b><br /></b></div>
<div>
<b>CS221 &#8211; Artificial Intelligence &#8211; Principles and Techniques (Prof. Liang and Prof. Sadigh)</b></div>
<div>
<ul style="text-align: left;">
<li>Difficulty: 4.5/5 (Heavy)</li>
<li>What to expect: </li>
<ul>
<li>This is one of the most &#8220;dense&#8221; classes I have come across at Stanford. The nature of the class is such that it is trying to fit in this huge umbrella of AI topics within a quarter &#8211; which is what makes it challenging. Topics include &#8211; </li>
<ul>
<li>Search</li>
<li>Markov Decision Process</li>
<li>Reinforcement Learning (RL)</li>
<li>Adversarial Games</li>
<li>Constraint Satisfaction problems</li>
<li>Bayesian Networks (BN)</li>
</ul>
<li>Amongst these, Reinforcement Learning and Bayesian Networks are conceptually heavy topics which require some extra effort.</li>
<li>That being said, the topics are interesting and makes you appreciate the latest trends in AI and draw parallels from traditional techniques. </li>
<li>Homeworks are weekly and can take time but are fun for the most part! You build your own Pacman game. </li>
</ul>
<li>My class project: </li>
<ul>
<li>Work in progress (to be updated shortly)</li>
</ul>
</ul>
<div>
</div>
</div>
<div>
Feel free to send in any other questions you would like for me to answer.</div>
<div>
</div>
<div>
Thank you,</div>
<div>
Ankit Chadha</div>
<div>
</div>
</div>
</div>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Two Decades After Its Release, ‘The Art Book for Children’ Gets a Vibrant Makeover</title>
		<link>https://www.sawberries.com/2024/04/27/the-art-book-for-children/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 06:28:43 +0000</pubDate>
				<category><![CDATA[art]]></category>
		<category><![CDATA[art history]]></category>
		<category><![CDATA[Books]]></category>
		<category><![CDATA[children's book]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/the-art-book-for-children/</guid>

					<description><![CDATA[All images courtesy of Phaidon, shared with permission First published in 1997, Phaidon’s The Art Book has long been a go-to source for introductions to some of the most influential artists. Spanning medieval to modern times, the volume contains more than 600 works and is available in 20 languages. About two decades ago, the iconic [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<div id="attachment_242979" style="width: 1930px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-242979" class="wp-image-242979 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-3.jpg" alt="an open book spread with an abstract yellow and purple painting and Hilma AF Klint and Painting Ideas and Beliefs on the left side" width="1920" height="1110" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-3.jpg 1920w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-3-640x370.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-3-960x555.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-3-1536x888.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></p>
<p id="caption-attachment-242979" class="wp-caption-text">All images courtesy of Phaidon, shared with permission</p>
</div>
<p>First published in 1997, Phaidon’s <a href="https://bookshop.org/a/96/9781838661342" target="_blank" rel="noopener"><em>The Art Book </em></a>has long been a go-to source for introductions to some of the most influential artists. Spanning medieval to modern times, the volume contains more than 600 works and is available in 20 languages. About two decades ago, the iconic title received another type of translation geared specifically toward younger art lovers when editors released <em>The Art Book for Children</em>.</p>
<p>That kids’ edition presents a bite-sized, accessible version of <em>The Art Book </em>and was recently updated and revised. The new volume features 30 artists from its predecessor along with 30 additions, bringing together the most significant names from art history like <a href="https://www.thisiscolossal.com/tags/katsushika-hokusai/">Katsushika Hokusai</a>, Jackson Pollock, and <a href="https://www.thisiscolossal.com/tags/frida-kahlo/">Frida Kahlo</a>. Each spread includes one or more works by each artist and a fun, informative text, inviting children to look closely and discover a variety of paintings, sculptures, photographs, and more.</p>
<p><em>The Art Book for Children</em> will be released on May 22 and is available for pre-order in the <a href="https://colossal.shop/collections/books/products/the-art-book-for-children" target="_blank" rel="noopener">Colossal Shop</a>.</p>
<p> </p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-242984 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-8.jpg" alt="a book spread featuring a cloud work by Georgia O'keefe with text about the piece" width="2000" height="1239" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-8.jpg 2000w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-8-640x396.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-8-960x595.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-8-1536x952.jpg 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<div id="attachment_242977" style="width: 1138px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-242977" class="wp-image-242977 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-1.jpg" alt="a print of a pink mountain and blue water and trees surrounding" width="1128" height="762" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-1.jpg 1128w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-1-640x432.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-1-960x649.jpg 960w" sizes="(max-width: 1128px) 100vw, 1128px"></p>
<p id="caption-attachment-242977" class="wp-caption-text">Katsushika Hokusai</p>
</div>
<div id="attachment_242983" style="width: 1930px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-242983" class="wp-image-242983 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-7.jpg" alt="vincent van gogh's iconic the starry night painting with a swirling blue sky and town below. plus a self portrait of the artist and brief text" width="1920" height="1189" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-7.jpg 1920w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-7-640x396.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-7-960x595.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-7-1536x951.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></p>
<p id="caption-attachment-242983" class="wp-caption-text">Vincent Van Gogh</p>
</div>
<p><img loading="lazy" decoding="async" class="wp-image-242980 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-4.jpg" alt="an open book spread with a large spider sculpture in a public place. on the left side the page says Louise Bourgeois and Artistic Arachnids" width="1920" height="1105" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-4.jpg 1920w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-4-640x368.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-4-960x553.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-4-1536x884.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></p>
<div id="attachment_242978" style="width: 1165px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-242978" class="wp-image-242978 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-2.jpg" alt="a painting of a woman in a gold gown and a man rising from his throne-like chair" width="1155" height="884" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-2.jpg 1155w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-2-640x490.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-2-960x735.jpg 960w" sizes="(max-width: 1155px) 100vw, 1155px"></p>
<p id="caption-attachment-242978" class="wp-caption-text">Artemisia Gentileschi, “Esther Before Ahasuerus” (1622), oil on canvas</p>
</div>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-242981 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-5.jpg" alt="an open book spread with a portrait of Frida Kahlo and her dog and monkey with text about her and Portraits with Pets on the left page" width="1920" height="1110" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-5.jpg 1920w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-5-640x370.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-5-960x555.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-5-1536x888.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-242982 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-6.jpg" alt="the cover of the art book for children" width="2000" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-6.jpg 2000w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-6-640x614.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-6-960x922.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/03/children-6-1536x1475.jpg 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p>Do stories and artists like this matter to you? Become a <a href="https://www.thisiscolossal.com/members">Colossal Member</a> today and support independent arts publishing for as little as $5 per month. The article <a href="https://www.thisiscolossal.com/2024/04/the-art-book-for-children/">Two Decades After Its Release, ‘The Art Book for Children’ Gets a Vibrant Makeover</a> appeared first on <a href="https://www.thisiscolossal.com/">Colossal</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Jason Limon Gets to the Heart of Human Emotion in His Soul-Stirring Skeleton Paintings</title>
		<link>https://www.sawberries.com/2024/04/27/jason-limon-paintings/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 06:28:42 +0000</pubDate>
				<category><![CDATA[anatomy]]></category>
		<category><![CDATA[art]]></category>
		<category><![CDATA[Jason Limon]]></category>
		<category><![CDATA[painting]]></category>
		<category><![CDATA[skeleton]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/jason-limon-paintings/</guid>

					<description><![CDATA[“Peas In A Pod” 10 x 10 inches. All images © Jason Limon, shared with permission Reaching toward universal experiences unclouded by specific identities, Jason Limon strips his recurring characters to the bare bones. The San Antonio-based artist (previously) continues his uncanny paintings of skeletons, who find themselves in precarious, startling, and genial situations. Recent [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<div id="attachment_246057" style="width: 1930px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246057" class="wp-image-246057 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-8.jpg" alt="two green skeletons use peas from a pod as their heads" width="1920" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-8.jpg 1920w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-8-640x640.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-8-960x960.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-8-150x150.jpg 150w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-8-1536x1536.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></p>
<p id="caption-attachment-246057" class="wp-caption-text">“Peas In A Pod” 10 x 10 inches. All images © Jason Limon, shared with permission</p>
</div>
<p>Reaching toward universal experiences unclouded by specific identities, <a href="https://www.limon-art.com/" target="_blank" rel="noopener">Jason Limon</a> strips his recurring characters to the bare bones. The San Antonio-based artist (<a href="https://www.thisiscolossal.com/tags/jason-limon/">previously</a>) continues his uncanny paintings of skeletons, who find themselves in precarious, startling, and genial situations. Recent works include “Peas In A Pod,” which features two friends adopting new heads from a large, curved shell. Similar smiling orbs appear in “The Right Grape” as a character chooses and fits the cheerful green fruit onto its neck.</p>
<p>Working in acrylic paint, Limon conjures myriad textures, whether through the deckled edges of a paper-craft structure or thin, crinkled plastic wrap. Combined with his muted palette of neutrals and jewel tones, these three-dimensional effects imbue the scenes with a vintage charm and a sense of timelessness.</p>
<p>Limon is currently working on a few personal projects, so keep an eye on <a href="https://www.instagram.com/jasonlimon/" target="_blank" rel="noopener">his Instagram</a> for updates. Find originals and prints in <a href="https://jason-limon-art.myshopify.com/" target="_blank" rel="noopener">his shop</a>.</p>
<p> </p>
<div id="attachment_246051" style="width: 1930px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246051" class="wp-image-246051 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-2.jpg" alt="a bronze papercut hand holds a skeleton figure holding a pink rose as it floats on blue water" width="1920" height="1440" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-2.jpg 1920w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-2-640x480.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-2-960x720.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-2-1536x1152.jpg 1536w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-2-285x214.jpg 285w" sizes="(max-width: 1920px) 100vw, 1920px"></p>
<p id="caption-attachment-246051" class="wp-caption-text">“Drift,” 12 x 9 inches</p>
</div>
<div id="attachment_246056" style="width: 1450px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246056" class="wp-image-246056 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-7.jpg" alt="a green skeleton picks up a grape from a bunch and fits it on its neck. all the grapes have faces" width="1440" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-7.jpg 1440w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-7-640x853.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-7-960x1280.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-7-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p id="caption-attachment-246056" class="wp-caption-text">“The Right Grape,” 9 x 12 inches</p>
</div>
<div id="attachment_246052" style="width: 1450px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246052" class="wp-image-246052 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-3.jpg" alt="a papercut box with a grim reaper/bat figure painted on it holds a skeleton figure in its arms" width="1440" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-3.jpg 1440w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-3-640x853.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-3-960x1280.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-3-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p id="caption-attachment-246052" class="wp-caption-text">“Succumb,” 6 x 8 inches</p>
</div>
<div id="attachment_246053" style="width: 1450px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246053" class="wp-image-246053 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-4.jpg" alt="an orange lightning bold pierces a cloud and three skeletons try to move it" width="1440" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-4.jpg 1440w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-4-640x853.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-4-960x1280.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-4-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p id="caption-attachment-246053" class="wp-caption-text">“Lightning,” 6 x 8 inches</p>
</div>
<div id="attachment_246054" style="width: 1546px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246054" class="wp-image-246054 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-5.jpg" alt="a skeleton is trapped in a garden that's in a frame. four gray skeletons are in the corner of the frame with orange and pink motifs surrounding" width="1536" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-5.jpg 1536w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-5-640x800.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-5-960x1200.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-5-1229x1536.jpg 1229w" sizes="(max-width: 1536px) 100vw, 1536px"></p>
<p id="caption-attachment-246054" class="wp-caption-text">“Framed II,” 8 x 10 inches</p>
</div>
<div id="attachment_246055" style="width: 1930px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246055" class="wp-image-246055 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-6.jpg" alt='a skeleton turns a knob attached to a large paper scroll with a skull on it that says "look around" on its forehead' width="1920" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-6.jpg 1920w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-6-640x640.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-6-960x960.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-6-150x150.jpg 150w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-6-1536x1536.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></p>
<p id="caption-attachment-246055" class="wp-caption-text">“Look Around,” 10 x 10 inches</p>
</div>
<div id="attachment_246050" style="width: 1450px" class="wp-caption alignnone"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-246050" class="wp-image-246050 size-full" src="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-1.jpg" alt="a skeleton rests in a translucent sleeping bag of stars and the moon with a pillow that says sleep" width="1440" height="1920" srcset="https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-1.jpg 1440w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-1-640x853.jpg 640w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-1-960x1280.jpg 960w, https://www.thisiscolossal.com/wp-content/uploads/2024/04/limon-1-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p id="caption-attachment-246050" class="wp-caption-text">“Sleepy,” 6 x 8 inches</p>
</div>
<p>Do stories and artists like this matter to you? Become a <a href="https://www.thisiscolossal.com/members">Colossal Member</a> today and support independent arts publishing for as little as $5 per month. The article <a href="https://www.thisiscolossal.com/2024/04/jason-limon-paintings/">Jason Limon Gets to the Heart of Human Emotion in His Soul-Stirring Skeleton Paintings</a> appeared first on <a href="https://www.thisiscolossal.com/">Colossal</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
