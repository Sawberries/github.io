<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Natural language processing &#8211; sawberries</title>
	<atom:link href="http://localhost/sawberries/category/ai/natural-language-processing/feed/?simply_static_page=1692616" rel="self" type="application/rss+xml" />
	<link>https://www.sawberries.com</link>
	<description>www.sawberry.com site</description>
	<lastBuildDate>Thu, 16 May 2024 07:55:43 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.3</generator>

<image>
	<url>https://www.sawberries.com/wp-content/uploads/2024/04/cropped-DALL·E-2024-04-26-12.21.04-A-512x512-favicon-design-that-incorporates-a-playful-twist-on-the-concept-of-a-strawberry-symbolizing-connections-between-people.-The-strawberry-shou-32x32.webp</url>
	<title>Natural language processing &#8211; sawberries</title>
	<link>https://www.sawberries.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Using ideas from game theory to improve the reliability of language models</title>
		<link>https://www.sawberries.com/2024/05/16/consensus-game-elevates-ai-text-comprehension-generation-skills-0514/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 16 May 2024 07:55:43 +0000</pubDate>
				<category><![CDATA[Algorithms]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Computer Science and Artificial Intelligence Laboratory (CSAIL)]]></category>
		<category><![CDATA[Computer science and technology]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Game theory]]></category>
		<category><![CDATA[Human-computer interaction]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT-IBM Watson AI Lab]]></category>
		<category><![CDATA[Natural language processing]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/16/consensus-game-elevates-ai-text-comprehension-generation-skills-0514/</guid>

					<description><![CDATA[Imagine you and a friend are playing a game where your goal is to communicate secret messages to each other using only cryptic sentences. Your friend&#8217;s job is to guess the secret message behind your sentences. Sometimes, you give clues directly, and other times, your friend has to guess the message by asking yes-or-no questions [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Imagine you and a friend are playing a game where your goal is to communicate secret messages to each other using only cryptic sentences. Your friend&#8217;s job is to guess the secret message behind your sentences. Sometimes, you give clues directly, and other times, your friend has to guess the message by asking yes-or-no questions about the clues you&#8217;ve given. The challenge is that both of you want to make sure you&#8217;re understanding each other correctly and agreeing on the secret message.</p>
<p>MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) researchers have created a similar &#8220;game&#8221; to help improve how AI understands and generates text. It is known as a “consensus game” and it involves two parts of an AI system — one part tries to generate sentences (like giving clues), and the other part tries to understand and evaluate those sentences (like guessing the secret message).</p>
<p>The researchers discovered that by treating this interaction as a game, where both parts of the AI work together under specific rules to agree on the right message, they could significantly improve the AI&#8217;s ability to give correct and coherent answers to questions. They tested this new game-like approach on a variety of tasks, such as reading comprehension, solving math problems, and carrying on conversations, and found that it helped the AI perform better across the board.</p>
<p>Traditionally, large language models answer one of two ways: generating answers directly from the model (generative querying) or using the model to score a set of predefined answers (discriminative querying), which can lead to differing and sometimes incompatible results. With the generative approach, &#8220;Who is the president of the United States?&#8221; might yield a straightforward answer like &#8220;Joe Biden.&#8221; However, a discriminative query could incorrectly dispute this fact when evaluating the same answer, such as &#8220;Barack Obama.&#8221;</p>
<p>So, how do we reconcile mutually incompatible scoring procedures to achieve coherent, efficient predictions? </p>
<p>&#8220;Imagine a new way to help language models understand and generate text, like a game. We&#8217;ve developed a training-free, game-theoretic method that treats the whole process as a complex game of clues and signals, where a generator tries to send the right message to a discriminator using natural language. Instead of chess pieces, they&#8217;re using words and sentences,&#8221; says Athul Jacob, an MIT PhD student in electrical engineering and computer science and CSAIL affiliate. &#8220;Our way to navigate this game is finding the &#8216;approximate equilibria,&#8217; leading to a new decoding algorithm called &#8216;equilibrium ranking.&#8217; It&#8217;s a pretty exciting demonstration of how bringing game-theoretic strategies into the mix can tackle some big challenges in making language models more reliable and consistent.&#8221;</p>
<p>When tested across many tasks, like reading comprehension, commonsense reasoning, math problem-solving, and dialogue, the team&#8217;s algorithm consistently improved how well these models performed. Using the ER algorithm with the LLaMA-7B model even outshone the results from much larger models. &#8220;Given that they are already competitive, that people have been working on it for a while, but the level of improvements we saw being able to outperform a model that&#8217;s 10 times the size was a pleasant surprise,&#8221; says Jacob. </p>
<p><strong>Game on</strong></p>
<p>&#8220;Diplomacy,&#8221; a strategic board game set in pre-World War I Europe, where players negotiate alliances, betray friends, and conquer territories without the use of dice — relying purely on skill, strategy, and interpersonal manipulation — recently had a second coming. In November 2022, computer scientists, including Jacob, developed “Cicero,” an AI agent that achieves human-level capabilities in the mixed-motive seven-player game, which requires the same aforementioned skills, but with natural language. The math behind this partially inspired the Consensus Game. </p>
<p>While the history of AI agents long predates when OpenAI&#8217;s software entered the chat in November 2022, it&#8217;s well documented that they can still cosplay as your well-meaning, yet pathological friend. </p>
<p>The consensus game system reaches equilibrium as an agreement, ensuring accuracy and fidelity to the model&#8217;s original insights. To achieve this, the method iteratively adjusts the interactions between the generative and discriminative components until they reach a consensus on an answer that accurately reflects reality and aligns with their initial beliefs. This approach effectively bridges the gap between the two querying methods. </p>
<p>In practice, implementing the consensus game approach to language model querying, especially for question-answering tasks, does involve significant computational challenges. For example, when using datasets like MMLU, which have thousands of questions and multiple-choice answers, the model must apply the mechanism to each query. Then, it must reach a consensus between the generative and discriminative components for every question and its possible answers. </p>
<p>The system did struggle with a grade school right of passage: math word problems. It couldn&#8217;t generate wrong answers, which is a critical component of understanding the process of coming up with the right one. </p>
<p>“The last few years have seen really impressive progress in both strategic decision-making and language generation from AI systems, but we’re just starting to figure out how to put the two together. Equilibrium ranking is a first step in this direction, but I think there’s a lot we’ll be able to do to scale this up to more complex problems,” says Jacob.   </p>
<p>An avenue of future work involves enhancing the base model by integrating the outputs of the current method. This is particularly promising since it can yield more factual and consistent answers across various tasks, including factuality and open-ended generation. The potential for such a method to significantly improve the base model&#8217;s performance is high, which could result in more reliable and factual outputs from ChatGPT and similar language models that people use daily. </p>
<p>&#8220;Even though modern language models, such as ChatGPT and Gemini, have led to solving various tasks through chat interfaces, the statistical decoding process that generates a response from such models has remained unchanged for decades,&#8221; says Google Research Scientist Ahmad Beirami, who was not involved in the work. &#8220;The proposal by the MIT researchers is an innovative game-theoretic framework for decoding from language models through solving the equilibrium of a consensus game. The significant performance gains reported in the research paper are promising, opening the door to a potential paradigm shift in language model decoding that may fuel a flurry of new applications.&#8221;</p>
<p>Jacob wrote the paper with MIT-IBM Watson Lab researcher Yikang Shen and MIT Department of Electrical Engineering and Computer Science assistant professors Gabriele Farina and Jacob Andreas, who is also a CSAIL member. They presented their work at the International Conference on Learning Representations (ICLR) earlier this month, where it was highlighted as a &#8220;spotlight paper.&#8221; The research also received a “best paper award” at the NeurIPS R0-FoMo Workshop in December 2023.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Natural language boosts LLM performance in coding, planning, and robotics</title>
		<link>https://www.sawberries.com/2024/05/02/natural-language-boosts-llm-performance-coding-planning-robotics-0501/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 07:25:27 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Brain and cognitive sciences]]></category>
		<category><![CDATA[Center for Brains Minds and Machines]]></category>
		<category><![CDATA[Computer Science and Artificial Intelligence Laboratory (CSAIL)]]></category>
		<category><![CDATA[Computer science and technology]]></category>
		<category><![CDATA[Computer vision]]></category>
		<category><![CDATA[Defense Advanced Research Projects Agency (DARPA)]]></category>
		<category><![CDATA[Department of Defense (DoD)]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Human-computer interaction]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT-IBM Watson AI Lab]]></category>
		<category><![CDATA[National Science Foundation (NSF)]]></category>
		<category><![CDATA[Natural language processing]]></category>
		<category><![CDATA[Programming]]></category>
		<category><![CDATA[programming languages]]></category>
		<category><![CDATA[Quest for Intelligence]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<category><![CDATA[School of Science]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/natural-language-boosts-llm-performance-coding-planning-robotics-0501/</guid>

					<description><![CDATA[Large language models (LLMs) are becoming increasingly useful for programming and robotics tasks, but for more complicated reasoning problems, the gap between these systems and humans looms large. Without the ability to learn new concepts like humans do, these systems fail to form good abstractions — essentially, high-level representations of complex concepts that skip less-important [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Large language models (LLMs) are becoming increasingly useful for programming and robotics tasks, but for more complicated reasoning problems, the gap between these systems and humans looms large. Without the ability to learn new concepts like humans do, these systems fail to form good abstractions — essentially, high-level representations of complex concepts that skip less-important details — and thus sputter when asked to do more sophisticated tasks.</p>
<p>Luckily, MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) researchers have found a treasure trove of abstractions within natural language. In three papers to be presented at the International Conference on Learning Representations this month, the group shows how our everyday words are a rich source of context for language models, helping them build better overarching representations for code synthesis, AI planning, and robotic navigation and manipulation.</p>
<p>The three separate frameworks build libraries of abstractions for their given task: <a href="https://arxiv.org/abs/2310.19791" target="_blank" rel="noopener">LILO</a> (library induction from language observations) can synthesize, compress, and document code; <a href="https://arxiv.org/abs/2312.08566" target="_blank" rel="noopener">Ada</a> (action domain acquisition) explores sequential decision-making for artificial intelligence agents; and <a href="https://arxiv.org/abs/2402.18759" target="_blank" rel="noopener">LGA</a> (language-guided abstraction) helps robots better understand their environments to develop more feasible plans. Each system is a neurosymbolic method, a type of AI that blends human-like neural networks and program-like logical components.</p>
<p><strong>LILO: A neurosymbolic framework that codes</strong></p>
<p>Large language models can be used to quickly write solutions to small-scale coding tasks, but cannot yet architect entire software libraries like the ones written by human software engineers. To take their software development capabilities further, AI models need to refactor (cut down and combine) code into libraries of succinct, readable, and reusable programs.</p>
<p>Refactoring tools like the previously developed MIT-led <a href="https://mlb2251.github.io/stitch_jul11.pdf" target="_blank" rel="noopener">Stitch</a> algorithm can automatically identify abstractions, so, in a nod to the Disney movie “Lilo &amp; Stitch,” CSAIL researchers combined these algorithmic refactoring approaches with LLMs. Their neurosymbolic method LILO uses a standard LLM to write code, then pairs it with Stitch to find abstractions that are comprehensively documented in a library.</p>
<p>LILO’s unique emphasis on natural language allows the system to do tasks that require human-like commonsense knowledge, such as identifying and removing all vowels from a string of code and drawing a snowflake. In both cases, the CSAIL system outperformed standalone LLMs, as well as a previous library learning algorithm from MIT called DreamCoder, indicating its ability to build a deeper understanding of the words within prompts. These encouraging results point to how LILO could assist with things like writing programs to manipulate documents like Excel spreadsheets, helping AI answer questions about visuals, and drawing 2D graphics.</p>
<p>“Language models prefer to work with functions that are named in natural language,” says Gabe Grand SM &#8217;23, an MIT PhD student in electrical engineering and computer science, CSAIL affiliate, and lead author on the research. “Our work creates more straightforward abstractions for language models and assigns natural language names and documentation to each one, leading to more interpretable code for programmers and improved system performance.”</p>
<p>When prompted on a programming task, LILO first uses an LLM to quickly propose solutions based on data it was trained on, and then the system slowly searches more exhaustively for outside solutions. Next, Stitch efficiently identifies common structures within the code and pulls out useful abstractions. These are then automatically named and documented by LILO, resulting in simplified programs that can be used by the system to solve more complex tasks.</p>
<p>The MIT framework writes programs in domain-specific programming languages, like Logo, a language developed at MIT in the 1970s to teach children about programming. Scaling up automated refactoring algorithms to handle more general programming languages like Python will be a focus for future research. Still, their work represents a step forward for how language models can facilitate increasingly elaborate coding activities.</p>
<p><strong>Ada: Natural language guides AI task planning</strong></p>
<p>Just like in programming, AI models that automate multi-step tasks in households and command-based video games lack abstractions. Imagine you’re cooking breakfast and ask your roommate to bring a hot egg to the table — they’ll intuitively abstract their background knowledge about cooking in your kitchen into a sequence of actions. In contrast, an LLM trained on similar information will still struggle to reason about what they need to build a flexible plan.</p>
<p>Named after the famed mathematician Ada Lovelace, who many consider the world’s first programmer, the CSAIL-led “Ada” framework makes headway on this issue by developing libraries of useful plans for virtual kitchen chores and gaming. The method trains on potential tasks and their natural language descriptions, then a language model proposes action abstractions from this dataset. A human operator scores and filters the best plans into a library, so that the best possible actions can be implemented into hierarchical plans for different tasks.</p>
<p>“Traditionally, large language models have struggled with more complex tasks because of problems like reasoning about abstractions,” says Ada lead researcher Lio Wong, an MIT graduate student in brain and cognitive sciences, CSAIL affiliate, and LILO coauthor. “But we can combine the tools that software engineers and roboticists use with LLMs to solve hard problems, such as decision-making in virtual environments.”</p>
<p>When the researchers incorporated the widely-used large language model GPT-4 into Ada, the system completed more tasks in a kitchen simulator and Mini Minecraft than the AI decision-making baseline “Code as Policies.” Ada used the background information hidden within natural language to understand how to place chilled wine in a cabinet and craft a bed. The results indicated a staggering 59 and 89 percent task accuracy improvement, respectively.</p>
<p>With this success, the researchers hope to generalize their work to real-world homes, with the hopes that Ada could assist with other household tasks and aid multiple robots in a kitchen. For now, its key limitation is that it uses a generic LLM, so the CSAIL team wants to apply a more powerful, fine-tuned language model that could assist with more extensive planning. Wong and her colleagues are also considering combining Ada with a robotic manipulation framework fresh out of CSAIL: LGA (language-guided abstraction).</p>
<p><strong>Language-guided abstraction: Representations for robotic tasks</strong></p>
<p>Andi Peng SM ’23, an MIT graduate student in electrical engineering and computer science and CSAIL affiliate, and her coauthors designed a method to help machines interpret their surroundings more like humans, cutting out unnecessary details in a complex environment like a factory or kitchen. Just like LILO and Ada, LGA has a novel focus on how natural language leads us to those better abstractions.</p>
<p>In these more unstructured environments, a robot will need some common sense about what it’s tasked with, even with basic training beforehand. Ask a robot to hand you a bowl, for instance, and the machine will need a general understanding of which features are important within its surroundings. From there, it can reason about how to give you the item you want. </p>
<p>In LGA’s case, humans first provide a pre-trained language model with a general task description using natural language, like “bring me my hat.” Then, the model translates this information into abstractions about the essential elements needed to perform this task. Finally, an imitation policy trained on a few demonstrations can implement these abstractions to guide a robot to grab the desired item.</p>
<p>Previous work required a person to take extensive notes on different manipulation tasks to pre-train a robot, which can be expensive. Remarkably, LGA guides language models to produce abstractions similar to those of a human annotator, but in less time. To illustrate this, LGA developed robotic policies to help Boston Dynamics’ Spot quadruped pick up fruits and throw drinks in a recycling bin. These experiments show how the MIT-developed method can scan the world and develop effective plans in unstructured environments, potentially guiding autonomous vehicles on the road and robots working in factories and kitchens.</p>
<p>“In robotics, a truth we often disregard is how much we need to refine our data to make a robot useful in the real world,” says Peng. “Beyond simply memorizing what’s in an image for training robots to perform tasks, we wanted to leverage computer vision and captioning models in conjunction with language. By producing text captions from what a robot sees, we show that language models can essentially build important world knowledge for a robot.”</p>
<p>The challenge for LGA is that some behaviors can’t be explained in language, making certain tasks underspecified. To expand how they represent features in an environment, Peng and her colleagues are considering incorporating multimodal visualization interfaces into their work. In the meantime, LGA provides a way for robots to gain a better feel for their surroundings when giving humans a helping hand. </p>
<p><strong>An “exciting frontier” in AI</strong></p>
<p>“Library learning represents one of the most exciting frontiers in artificial intelligence, offering a path towards discovering and reasoning over compositional abstractions,” says assistant professor at the University of Wisconsin-Madison Robert Hawkins, who was not involved with the papers. Hawkins notes that previous techniques exploring this subject have been “too computationally expensive to use at scale” and have an issue with the lambdas, or keywords used to describe new functions in many languages, that they generate. “They tend to produce opaque &#8216;lambda salads,&#8217; big piles of hard-to-interpret functions. These recent papers demonstrate a compelling way forward by placing large language models in an interactive loop with symbolic search, compression, and planning algorithms. This work enables the rapid acquisition of more interpretable and adaptive libraries for the task at hand.”</p>
<p>By building libraries of high-quality code abstractions using natural language, the three neurosymbolic methods make it easier for language models to tackle more elaborate problems and environments in the future. This deeper understanding of the precise keywords within a prompt presents a path forward in developing more human-like AI models.</p>
<p>MIT CSAIL members are senior authors for each paper: Joshua Tenenbaum, a professor of brain and cognitive sciences, for both LILO and Ada; Julie Shah, head of the Department of Aeronautics and Astronautics, for LGA; and Jacob Andreas, associate professor of electrical engineering and computer science, for all three. The additional MIT authors are all PhD students: Maddy Bowers and Theo X. Olausson for LILO, Jiayuan Mao and Pratyusha Sharma for Ada, and Belinda Z. Li for LGA. Muxin Liu of Harvey Mudd College was a coauthor on LILO; Zachary Siegel of Princeton University, Jaihai Feng of the University of California at Berkeley, and Noa Korneev of Microsoft were coauthors on Ada; and Ilia Sucholutsky, Theodore R. Sumers, and Thomas L. Griffiths of Princeton were coauthors on LGA. </p>
<p>LILO and Ada were supported, in part, by ​​MIT Quest for Intelligence, the MIT-IBM Watson AI Lab, Intel, U.S. Air Force Office of Scientific Research, the U.S. Defense Advanced Research Projects Agency, and the U.S. Office of Naval Research, with the latter project also receiving funding from the Center for Brains, Minds and Machines. LGA received funding from the U.S. National Science Foundation, Open Philanthropy, the Natural Sciences and Engineering Research Council of Canada, and the U.S. Department of Defense.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Implementing Query2Model: Simplifying Machine Learning</title>
		<link>https://www.sawberries.com/2024/04/25/implementing-query2model-simplifying-machine-learning/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 08:58:30 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[blogathon]]></category>
		<category><![CDATA[chatbot]]></category>
		<category><![CDATA[ChatGPT]]></category>
		<category><![CDATA[dat science]]></category>
		<category><![CDATA[Ethereum]]></category>
		<category><![CDATA[hugchat]]></category>
		<category><![CDATA[HuggingChat]]></category>
		<category><![CDATA[Intermediate]]></category>
		<category><![CDATA[library in python]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Natural Language]]></category>
		<category><![CDATA[Natural language processing]]></category>
		<category><![CDATA[NLP]]></category>
		<category><![CDATA[pipeline]]></category>
		<category><![CDATA[Prompt Engineering]]></category>
		<category><![CDATA[query2model]]></category>
		<category><![CDATA[training]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/25/implementing-query2model-simplifying-machine-learning/</guid>

					<description><![CDATA[Introduction Embark on an exciting journey into the world of effortless machine learning with “Query2Model”! This innovative blog introduces a user-friendly interface where complex tasks are simplified into plain language queries. Explore the fusion of natural language processing and advanced AI models, transforming intricate tasks into straightforward conversations. Join us as we delve into the [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction Embark on an exciting journey into the world of effortless machine learning with “Query2Model”! This innovative blog introduces a user-friendly interface where complex tasks are simplified into plain language queries. Explore the fusion of natural language processing and advanced AI models, transforming intricate tasks into straightforward conversations. Join us as we delve into the […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/implementing-query2model-simplifying-machine-learning/">Implementing Query2Model: Simplifying Machine Learning</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
