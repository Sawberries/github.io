<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Artificial Intelligence &#8211; sawberries</title>
	<atom:link href="http://localhost/sawberries/category/ai/artificial-intelligence/feed/?simply_static_page=71029" rel="self" type="application/rss+xml" />
	<link>https://www.sawberries.com</link>
	<description>www.sawberry.com site</description>
	<lastBuildDate>Sun, 28 Apr 2024 03:38:27 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.2</generator>

<image>
	<url>https://www.sawberries.com/wp-content/uploads/2024/04/cropped-DALL·E-2024-04-26-12.21.04-A-512x512-favicon-design-that-incorporates-a-playful-twist-on-the-concept-of-a-strawberry-symbolizing-connections-between-people.-The-strawberry-shou-32x32.webp</url>
	<title>Artificial Intelligence &#8211; sawberries</title>
	<link>https://www.sawberries.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>How to Transition your Career from Non Tech Field to Generative AI?</title>
		<link>https://www.sawberries.com/2024/04/28/transition-your-career-from-non-tech-field-to-generative-ai/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sun, 28 Apr 2024 03:38:27 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Beginner]]></category>
		<category><![CDATA[Career]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Large Language Models]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Python]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/28/transition-your-career-from-non-tech-field-to-generative-ai/</guid>

					<description><![CDATA[Introduction In today’s rapidly evolving world, the term ‘Generative AI’ is on everyone’s lips. Studies reveal that Generative AI is becoming indispensable in the workplace, with the market projected to reach $1.3 trillion by 2032. If you’ve been considering a career transition from a non-tech field to Generative AI, now is the time! This article explores the [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction In today’s rapidly evolving world, the term ‘Generative AI’ is on everyone’s lips. Studies reveal that Generative AI is becoming indispensable in the workplace, with the market projected to reach $1.3 trillion by 2032. If you’ve been considering a career transition from a non-tech field to Generative AI, now is the time! This article explores the […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/transition-your-career-from-non-tech-field-to-generative-ai/">How to Transition your Career from Non Tech Field to Generative AI?</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Nvidia Acquires Run:ai to Boost AI Infrastructure Efficiency</title>
		<link>https://www.sawberries.com/2024/04/27/nvidia-acquires-runai-to-boost-ai-infrastructure-efficiency/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 06:28:38 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[NVIDIA]]></category>
		<category><![CDATA[Run:ai]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/nvidia-acquires-runai-to-boost-ai-infrastructure-efficiency/</guid>

					<description><![CDATA[Nvidia had recently acquired Run:ai, an Israeli startup specializing in AI workload management. This move underscores the increasing significance of Kubernetes in generative AI. Through this, Nvidia aims to address the challenges associated with GPU resource utilization in AI infrastructure. Let’s delve into the details of this acquisition and its implications for the AI and [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Nvidia had recently acquired Run:ai, an Israeli startup specializing in AI workload management. This move underscores the increasing significance of Kubernetes in generative AI. Through this, Nvidia aims to address the challenges associated with GPU resource utilization in AI infrastructure. Let’s delve into the details of this acquisition and its implications for the AI and […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/nvidia-acquires-runai-to-boost-ai-infrastructure-efficiency/">Nvidia Acquires Run:ai to Boost AI Infrastructure Efficiency</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Top 7 AI Healthcare Solution Providers</title>
		<link>https://www.sawberries.com/2024/04/27/ai-healthcare-solution-providers/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 06:28:37 +0000</pubDate>
				<category><![CDATA[AI medical diagnosis]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Beginner]]></category>
		<category><![CDATA[diagnosis]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[health care providers]]></category>
		<category><![CDATA[Healthcare]]></category>
		<category><![CDATA[healthcare solution]]></category>
		<category><![CDATA[Listicle]]></category>
		<category><![CDATA[treatement]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/ai-healthcare-solution-providers/</guid>

					<description><![CDATA[Introduction Artificial Intelligence technology is reshaping treatment, patient care and diagnosis in the healthcare industry. Precision medicine platforms and portable ultrasound equipment are examples of these technology. Healthcare professionals can now offer patients individualized, effective, and precise care because to developments in artificial intelligence. This article offers insights into the newest advancements in AI-driven medical [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction Artificial Intelligence technology is reshaping treatment, patient care and diagnosis in the healthcare industry. Precision medicine platforms and portable ultrasound equipment are examples of these technology. Healthcare professionals can now offer patients individualized, effective, and precise care because to developments in artificial intelligence. This article offers insights into the newest advancements in AI-driven medical […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/ai-healthcare-solution-providers/">Top 7 AI Healthcare Solution Providers</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Apple Introduces OpenELM: Open-Source AI Models for On-Device Processing</title>
		<link>https://www.sawberries.com/2024/04/27/apple-introduces-openelm-open-source-ai-models-for-on-device-processing/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sat, 27 Apr 2024 06:28:37 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/27/apple-introduces-openelm-open-source-ai-models-for-on-device-processing/</guid>

					<description><![CDATA[Apple has recently unveiled OpenELM, a family of open-source language models optimized for on-device processing. This model has been made open source, encouraging free usage and collaboration. Apple’s move towards transparency aims to empower developers and researchers while enhancing user privacy. Let’s find out more about this new release. Also Read: Apple Boosts AI Capabilities [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Apple has recently unveiled OpenELM, a family of open-source language models optimized for on-device processing. This model has been made open source, encouraging free usage and collaboration. Apple’s move towards transparency aims to empower developers and researchers while enhancing user privacy. Let’s find out more about this new release. Also Read: Apple Boosts AI Capabilities […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/apple-introduces-openelm-open-source-ai-models-for-on-device-processing/">Apple Introduces OpenELM: Open-Source AI Models for On-Device Processing</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>New Chinese Model Outperforms GPT-4 Turbo!</title>
		<link>https://www.sawberries.com/2024/04/26/chinese-ai-model-sensetime-sensenova-outperforms-gpt-4-turbo/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Fri, 26 Apr 2024 10:32:32 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[AI model]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[China]]></category>
		<category><![CDATA[Coding]]></category>
		<category><![CDATA[GPT]]></category>
		<category><![CDATA[GPT-4 Turbo]]></category>
		<category><![CDATA[intelligence]]></category>
		<category><![CDATA[Mathematics]]></category>
		<category><![CDATA[Models]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[SenseNova 5.0]]></category>
		<category><![CDATA[SenseTime]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/26/chinese-ai-model-sensetime-sensenova-outperforms-gpt-4-turbo/</guid>

					<description><![CDATA[SenseTime, a leading AI company based in China, has launched its latest model, SenseNova 5.0, marking a significant advancement in artificial intelligence. This new model has been shown to outperform many powerful large language models, including GPT-4 Turbo. Despite the lack of buzz surrounding its release, it looks promising in revolutionizing various industries with its [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>SenseTime, a leading AI company based in China, has launched its latest model, SenseNova 5.0, marking a significant advancement in artificial intelligence. This new model has been shown to outperform many powerful large language models, including GPT-4 Turbo. Despite the lack of buzz surrounding its release, it looks promising in revolutionizing various industries with its […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/chinese-ai-model-sensetime-sensenova-outperforms-gpt-4-turbo/">New Chinese Model Outperforms GPT-4 Turbo!</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
<p><!-- Disqus thread link for post ID  --></p>
<div id='disqus_thread'></div>
<p><script>var disqus_config = function () { this.page.url = 'www.sawberries.com/?p='; this.page.identifier = ''; }; (function() { var d = document, s = d.createElement('script'); s.src = 'https://www-sawberries-com.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })();</script><br />
<noscript>Please enable JavaScript to view the <a href='https://disqus.com/?ref_noscript'>comments powered by Disqus.</a></noscript></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Cohere Launches Toolkit to Expedite Generative AI Application Development</title>
		<link>https://www.sawberries.com/2024/04/25/cohere-launches-toolkit-to-expedite-generative-ai-application-development/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 21:02:17 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[AI app]]></category>
		<category><![CDATA[AI App Building]]></category>
		<category><![CDATA[AI toolkit]]></category>
		<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cohere]]></category>
		<category><![CDATA[deployment]]></category>
		<category><![CDATA[Features]]></category>
		<category><![CDATA[Generative AI Toolkit]]></category>
		<category><![CDATA[Models]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Toolkit]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/25/cohere-launches-toolkit-to-expedite-generative-ai-application-development/</guid>

					<description><![CDATA[Cohere, a leading figure in AI innovation, has unveiled a new toolkit for enterprise AI. This new toolkit is aimed at speeding up the pace of generative AI application development within the enterprise sphere. It offers developers a comprehensive set of tools and resources to expedite their projects. It further promises to streamline the intricate [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Cohere, a leading figure in AI innovation, has unveiled a new toolkit for enterprise AI. This new toolkit is aimed at speeding up the pace of generative AI application development within the enterprise sphere. It offers developers a comprehensive set of tools and resources to expedite their projects. It further promises to streamline the intricate […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/cohere-launches-toolkit-to-expedite-generative-ai-application-development/">Cohere Launches Toolkit to Expedite Generative AI Application Development</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Meet Malar, India’s First Autonomous AI Professor</title>
		<link>https://www.sawberries.com/2024/04/25/meet-malar-teacher-indias-first-autonomous-ai-professor/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 12:13:48 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[AI in India]]></category>
		<category><![CDATA[AI professor]]></category>
		<category><![CDATA[Anna University]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Chennai]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[HaiVE]]></category>
		<category><![CDATA[india]]></category>
		<category><![CDATA[Interviews]]></category>
		<category><![CDATA[Malar Teacher]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Startups]]></category>
		<category><![CDATA[Technology]]></category>
		<category><![CDATA[Whatsapp]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/25/meet-malar-teacher-indias-first-autonomous-ai-professor/</guid>

					<description><![CDATA[Two months after Kerala got its first AI teacher, Chennai researchers have developed the country’s first AI Professor! “Malar Teacher,” as she is named, is said to be the world’s first autonomous AI university professor. Malar is fully trained on the complete engineering syllabus of Anna University, ushering in a new era of teaching. This [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Two months after Kerala got its first AI teacher, Chennai researchers have developed the country’s first AI Professor! “Malar Teacher,” as she is named, is said to be the world’s first autonomous AI university professor. Malar is fully trained on the complete engineering syllabus of Anna University, ushering in a new era of teaching. This […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/meet-malar-teacher-indias-first-autonomous-ai-professor/">Meet Malar, India’s First Autonomous AI Professor</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Convert Blurry Videos to HD with Adobe’s New AI</title>
		<link>https://www.sawberries.com/2024/04/25/adobe-videogigagan-elevates-video-quality-using-ai/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 12:13:47 +0000</pubDate>
				<category><![CDATA[adobe]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[AI video editing]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[challenges]]></category>
		<category><![CDATA[Features]]></category>
		<category><![CDATA[GANs]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Technology]]></category>
		<category><![CDATA[video]]></category>
		<category><![CDATA[VideoGigaGAN]]></category>
		<category><![CDATA[Videos]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/25/adobe-videogigagan-elevates-video-quality-using-ai/</guid>

					<description><![CDATA[Adobe’s latest innovation in AI technology, VideoGigaGAN, promises to revolutionize video upscaling by enhancing resolution without compromising on quality. With its new approach, Adobe aims to address the longstanding challenges of blurry videos. It presents a solution that offers remarkable results in converting blurry videos into HD. Let’s find out more about its features and [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Adobe’s latest innovation in AI technology, VideoGigaGAN, promises to revolutionize video upscaling by enhancing resolution without compromising on quality. With its new approach, Adobe aims to address the longstanding challenges of blurry videos. It presents a solution that offers remarkable results in converting blurry videos into HD. Let’s find out more about its features and […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/adobe-videogigagan-elevates-video-quality-using-ai/">Convert Blurry Videos to HD with Adobe’s New AI</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>This tiny chip can safeguard user data while enabling efficient computing on a smartphone</title>
		<link>https://www.sawberries.com/2024/04/25/this-tiny-chip-can-safeguard-user-data-while-enabling-efficient-computing-on-a-smartphone/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 08:58:32 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Computer science and technology]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Data]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Electronics]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT-IBM Watson AI Lab]]></category>
		<category><![CDATA[National Science Foundation (NSF)]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/25/this-tiny-chip-can-safeguard-user-data-while-enabling-efficient-computing-on-a-smartphone/</guid>

					<description><![CDATA[Health-monitoring apps can help people manage chronic diseases or stay on track with fitness goals, using nothing more than a smartphone. However, these apps can be slow and energy-inefficient because the vast machine-learning models that power them must be shuttled between a smartphone and a central memory server. Engineers often speed things up using hardware [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Health-monitoring apps can help people manage chronic diseases or stay on track with fitness goals, using nothing more than a smartphone. However, these apps can be slow and energy-inefficient because the vast machine-learning models that power them must be shuttled between a smartphone and a central memory server.</p>
<p>Engineers often speed things up using hardware that reduces the need to move so much data back and forth. While these machine-learning accelerators can streamline computation, they are susceptible to attackers who can steal secret information.</p>
<p>To reduce this vulnerability, researchers from MIT and the MIT-IBM Watson AI Lab created a machine-learning accelerator that is resistant to the two most common types of attacks. Their chip can keep a user’s health records, financial information, or other sensitive data private while still enabling huge AI models to run efficiently on devices.</p>
<p>The team developed several optimizations that enable strong security while only slightly slowing the device. Moreover, the added security does not impact the accuracy of computations. This machine-learning accelerator could be particularly beneficial for demanding AI applications like augmented and virtual reality or autonomous driving.</p>
<p>While implementing the chip would make a device slightly more expensive and less energy-efficient, that is sometimes a worthwhile price to pay for security, says lead author Maitreyi Ashok, an electrical engineering and computer science (EECS) graduate student at MIT.</p>
<p>“It is important to design with security in mind from the ground up. If you are trying to add even a minimal amount of security after a system has been designed, it is prohibitively expensive. We were able to effectively balance a lot of these tradeoffs during the design phase,” says Ashok.</p>
<p>Her co-authors include Saurav Maji, an EECS graduate student; Xin Zhang and John Cohn of the MIT-IBM Watson AI Lab; and senior author Anantha Chandrakasan, MIT’s chief innovation and strategy officer, dean of the School of Engineering, and the Vannevar Bush Professor of EECS. The research will be presented at the IEEE Custom Integrated Circuits Conference.</p>
<p><strong>Side-channel susceptibility</strong></p>
<p>The researchers targeted a type of machine-learning accelerator called digital in-memory compute. A digital IMC chip performs computations inside a device’s memory, where pieces of a machine-learning model are stored after being moved over from a central server.</p>
<p>The entire model is too big to store on the device, but by breaking it into pieces and reusing those pieces as much as possible, IMC chips reduce the amount of data that must be moved back and forth.</p>
<p>But IMC chips can be susceptible to hackers. In a side-channel attack, a hacker monitors the chip’s power consumption and uses statistical techniques to reverse-engineer data as the chip computes. In a bus-probing attack, the hacker can steal bits of the model and dataset by probing the communication between the accelerator and the off-chip memory.</p>
<p>Digital IMC speeds computation by performing millions of operations at once, but this complexity makes it tough to prevent attacks using traditional security measures, Ashok says.</p>
<p>She and her collaborators took a three-pronged approach to blocking side-channel and bus-probing attacks.</p>
<p>First, they employed a security measure where data in the IMC are split into random pieces. For instance, a bit zero might be split into three bits that still equal zero after a logical operation. The IMC never computes with all pieces in the same operation, so a side-channel attack could never reconstruct the real information.</p>
<p>But for this technique to work, random bits must be added to split the data. Because digital IMC performs millions of operations at once, generating so many random bits would involve too much computing. For their chip, the researchers found a way to simplify computations, making it easier to effectively split data while eliminating the need for random bits.</p>
<p>Second, they prevented bus-probing attacks using a lightweight cipher that encrypts the model stored in off-chip memory. This lightweight cipher only requires simple computations. In addition, they only decrypted the pieces of the model stored on the chip when necessary.</p>
<p>Third, to improve security, they generated the key that decrypts the cipher directly on the chip, rather than moving it back and forth with the model. They generated this unique key from random variations in the chip that are introduced during manufacturing, using what is known as a physically unclonable function.</p>
<p>“Maybe one wire is going to be a little bit thicker than another. We can use these variations to get zeros and ones out of a circuit. For every chip, we can get a random key that should be consistent because these random properties shouldn’t change significantly over time,” Ashok explains.</p>
<p>They reused the memory cells on the chip, leveraging the imperfections in these cells to generate the key. This requires less computation than generating a key from scratch.</p>
<p>“As security has become a critical issue in the design of edge devices, there is a need to develop a complete system stack focusing on secure operation. This work focuses on security for machine-learning workloads and describes a digital processor that uses cross-cutting optimization. It incorporates encrypted data access between memory and processor, approaches to preventing side-channel attacks using randomization, and exploiting variability to generate unique codes. Such designs are going to be critical in future mobile devices,” says Chandrakasan.</p>
<p><strong>Safety testing</strong></p>
<p>To test their chip, the researchers took on the role of hackers and tried to steal secret information using side-channel and bus-probing attacks.</p>
<p>Even after making millions of attempts, they couldn’t reconstruct any real information or extract pieces of the model or dataset. The cipher also remained unbreakable. By contrast, it took only about 5,000 samples to steal information from an unprotected chip.</p>
<p>The addition of security did reduce the energy efficiency of the accelerator, and it also required a larger chip area, which would make it more expensive to fabricate.</p>
<p>The team is planning to explore methods that could reduce the energy consumption and size of their chip in the future, which would make it easier to implement at scale.</p>
<p>“As it becomes too expensive, it becomes harder to convince someone that security is critical. Future work could explore these tradeoffs. Maybe we could make it a little less secure but easier to implement and less expensive,” Ashok says.</p>
<p>The research is funded, in part, by the MIT-IBM Watson AI Lab, the National Science Foundation, and a Mathworks Engineering Fellowship.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Mapping the brain pathways of visual memorability</title>
		<link>https://www.sawberries.com/2024/04/25/mapping-the-brain-pathways-of-visual-memorability/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 08:58:32 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Brain and cognitive sciences]]></category>
		<category><![CDATA[Computer Science and Artificial Intelligence Laboratory (CSAIL)]]></category>
		<category><![CDATA[Computer science and technology]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Functional magnetic resonance imaging (fMRI)]]></category>
		<category><![CDATA[Image Processing]]></category>
		<category><![CDATA[Imaging]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT-IBM Watson AI Lab]]></category>
		<category><![CDATA[Neuroscience]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<category><![CDATA[Vision]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/25/mapping-the-brain-pathways-of-visual-memorability/</guid>

					<description><![CDATA[For nearly a decade, a team of MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) researchers have been seeking to uncover why certain images persist in a people&#8217;s minds, while many others fade. To do this, they set out to map the spatio-temporal brain dynamics involved in recognizing a visual image. And now for the [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>For nearly a decade, a team of MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) researchers have been seeking to uncover why certain images persist in a people&#8217;s minds, while many others fade. To do this, they set out to map the spatio-temporal brain dynamics involved in recognizing a visual image. And now for the first time, scientists harnessed the combined strengths of magnetoencephalography (MEG), which captures the timing of brain activity, and functional magnetic resonance imaging (fMRI), which identifies active brain regions, to precisely determine when and where the brain processes a memorable image. </p>
<p>Their open-access study, <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002564" target="_blank" rel="noopener">published this month in <em>PLOS Biology</em></a>, used 78 pairs of images matched for the same concept but differing in their memorability scores — one was highly memorable and the other was easy to forget. These images were shown to 15 subjects, with scenes of skateboarding, animals in various environments, everyday objects like cups and chairs, natural landscapes like forests and beaches, urban scenes of streets and buildings, and faces displaying different expressions. What they found was that a more distributed network of brain regions than previously thought are actively involved in the encoding and retention processes that underpin memorability. </p>
<p>“People tend to remember some images better than others, even when they are conceptually similar, like different scenes of a person skateboarding,” says Benjamin Lahner, an MIT PhD student in electrical engineering and computer science, CSAIL affiliate, and first author of the study. “We&#8217;ve identified a brain signature of visual memorability that emerges around 300 milliseconds after seeing an image, involving areas across the ventral occipital cortex and temporal cortex, which processes information like color perception and object recognition. This signature indicates that highly memorable images prompt stronger and more sustained brain responses, especially in regions like the early visual cortex, which we previously underestimated in memory processing.”</p>
<p>While highly memorable images maintain a higher and more sustained response for about half a second, the response to less memorable images quickly diminishes. This insight, Lahner elaborated, could redefine our understanding of how memories form and persist. The team envisions this research holding potential for future clinical applications, particularly in early diagnosis and treatment of memory-related disorders. </p>
<p>The MEG/fMRI fusion method, developed in the lab of CSAIL Senior Research Scientist Aude Oliva, adeptly captures the brain&#8217;s spatial and temporal dynamics, overcoming the traditional constraints of either spatial or temporal specificity. The fusion method had a little help from its machine-learning friend, to better examine and compare the brain&#8217;s activity when looking at various images. They created a “representational matrix,” which is like a detailed chart, showing how similar neural responses are in various brain regions. This chart helped them identify the patterns of where and when the brain processes what we see.</p>
<p>Picking the conceptually similar image pairs with high and low memorability scores was the crucial ingredient to unlocking these insights into memorability. Lahner explained the process of aggregating behavioral data to assign memorability scores to images, where they curated a diverse set of high- and low-memorability images with balanced representation across different visual categories. </p>
<p>Despite strides made, the team notes a few limitations. While this work can identify brain regions showing significant memorability effects, it cannot elucidate the regions&#8217; function in how it is contributing to better encoding/retrieval from memory.</p>
<p>“Understanding the neural underpinnings of memorability opens up exciting avenues for clinical advancements, particularly in diagnosing and treating memory-related disorders early on,” says Oliva. “The specific brain signatures we&#8217;ve identified for memorability could lead to early biomarkers for Alzheimer&#8217;s disease and other dementias. This research paves the way for novel intervention strategies that are finely tuned to the individual&#8217;s neural profile, potentially transforming the therapeutic landscape for memory impairments and significantly improving patient outcomes.”</p>
<p>“These findings are exciting because they give us insight into what is happening in the brain between seeing something and saving it into memory,” says Wilma Bainbridge, assistant professor of psychology at the University of Chicago, who was not involved in the study. “The researchers here are picking up on a cortical signal that reflects what&#8217;s important to remember, and what can be forgotten early on.” </p>
<p>Lahner and Oliva, who is also the director of strategic industry engagement at the MIT Schwarzman College of Computing, MIT director of the MIT-IBM Watson AI Lab, and CSAIL principal investigator, join Western University Assistant Professor Yalda Mohsenzadeh and York University researcher Caitlin Mullin on the paper. The team acknowledges a shared instrument grant from the National Institutes of Health, and their work was funded by the Vannevar Bush Faculty Fellowship via an Office of Naval Research grant, a National Science Foundation award, Multidisciplinary University Research Initiative award via an Army Research Office grant, and the EECS MathWorks Fellowship. Their paper is published in <em>PLOS Biology</em>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
