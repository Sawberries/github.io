<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Artificial Intelligence &#8211; sawberries</title>
	<atom:link href="http://localhost/sawberries/category/ai/artificial-intelligence/feed/?simply_static_page=395652" rel="self" type="application/rss+xml" />
	<link>https://www.sawberries.com</link>
	<description>www.sawberry.com site</description>
	<lastBuildDate>Thu, 02 May 2024 21:01:14 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.2</generator>

<image>
	<url>https://www.sawberries.com/wp-content/uploads/2024/04/cropped-DALL·E-2024-04-26-12.21.04-A-512x512-favicon-design-that-incorporates-a-playful-twist-on-the-concept-of-a-strawberry-symbolizing-connections-between-people.-The-strawberry-shou-32x32.webp</url>
	<title>Artificial Intelligence &#8211; sawberries</title>
	<link>https://www.sawberries.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>World’s First Autonomous Car Race Held at Abu Dhabi’s Yas Marina</title>
		<link>https://www.sawberries.com/2024/05/02/worlds-first-autonomous-car-race-held-at-abu-dhabis-yas-marina/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 21:01:14 +0000</pubDate>
				<category><![CDATA[A2RL]]></category>
		<category><![CDATA[Abu Dhabi]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Automobiles]]></category>
		<category><![CDATA[autonomous care race]]></category>
		<category><![CDATA[autonomous cars]]></category>
		<category><![CDATA[autonomous driving]]></category>
		<category><![CDATA[challenges]]></category>
		<category><![CDATA[event]]></category>
		<category><![CDATA[motor sporting]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Technology]]></category>
		<category><![CDATA[Yas Marina]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/worlds-first-autonomous-car-race-held-at-abu-dhabis-yas-marina/</guid>

					<description><![CDATA[Can you imagine a car race without any drivers? Well, it’s no longer imagination, but a reality now! That’s right, the world witnessed the first-ever professional autonomous car race over the weekend. The Abu Dhabi Autonomous Racing League (A2RL) held at Yas Marina marked a significant leap in the motor racing world. With autonomous cars [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Can you imagine a car race without any drivers? Well, it’s no longer imagination, but a reality now! That’s right, the world witnessed the first-ever professional autonomous car race over the weekend. The Abu Dhabi Autonomous Racing League (A2RL) held at Yas Marina marked a significant leap in the motor racing world. With autonomous cars […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/worlds-first-autonomous-car-race-held-at-abu-dhabis-yas-marina/">World’s First Autonomous Car Race Held at Abu Dhabi’s Yas Marina</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Explore the World through your Photos with GeoSpy.AI</title>
		<link>https://www.sawberries.com/2024/05/02/explore-the-world-through-your-photos-with-geospy-ai/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 15:01:16 +0000</pubDate>
				<category><![CDATA[AI Tools]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Beginner]]></category>
		<category><![CDATA[Find Location]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GeoSpy.AI]]></category>
		<category><![CDATA[supertools]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/explore-the-world-through-your-photos-with-geospy-ai/</guid>

					<description><![CDATA[Introduction In the age of advanced technology, GeoSpy.AI emerges as an AI powered intel platform that utilizes the power of geospatial vision large language models (LLMs) to predict locations from photos. Whether it’s a snapshot of a suburban street, a rural landscape, or a city corner, GeoSpy.AI can pinpoint the coordinates of the location within [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction In the age of advanced technology, GeoSpy.AI emerges as an AI powered intel platform that utilizes the power of geospatial vision large language models (LLMs) to predict locations from photos. Whether it’s a snapshot of a suburban street, a rural landscape, or a city corner, GeoSpy.AI can pinpoint the coordinates of the location within […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/explore-the-world-through-your-photos-with-geospy-ai/">Explore the World through your Photos with GeoSpy.AI</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Gecko by Google: Pioneering the Next Generation of Text Embedding Models</title>
		<link>https://www.sawberries.com/2024/05/02/gecko-by-google/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 15:01:15 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[Applications]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[blockchain]]></category>
		<category><![CDATA[challenges]]></category>
		<category><![CDATA[Embedding]]></category>
		<category><![CDATA[Guide]]></category>
		<category><![CDATA[Intermediate]]></category>
		<category><![CDATA[language models]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Models]]></category>
		<category><![CDATA[NLP]]></category>
		<category><![CDATA[Text]]></category>
		<category><![CDATA[training]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/gecko-by-google/</guid>

					<description><![CDATA[Introduction Welcome to the world of text embeddings where text is converted into numbers! This world has recently been turned around by the distillation of large language models (LLMs) into efficient and compact forms. Google’s latest innovation, Gecko, is the lastest advancement in this technology, revolutionizing the way we handle textual data. This article explores [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction Welcome to the world of text embeddings where text is converted into numbers! This world has recently been turned around by the distillation of large language models (LLMs) into efficient and compact forms. Google’s latest innovation, Gecko, is the lastest advancement in this technology, revolutionizing the way we handle textual data. This article explores […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/gecko-by-google/">Gecko by Google: Pioneering the Next Generation of Text Embedding Models</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Meet Victoria Shi, the World’s First AI-Generated Foreign Minister</title>
		<link>https://www.sawberries.com/2024/05/02/meet-victoria-shi-the-worlds-first-ai-generated-foreign-minister/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 15:01:13 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[AI Avatar]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[communication]]></category>
		<category><![CDATA[digital]]></category>
		<category><![CDATA[efficiency]]></category>
		<category><![CDATA[Ministry]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[resources]]></category>
		<category><![CDATA[Technology]]></category>
		<category><![CDATA[Ukraine]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/meet-victoria-shi-the-worlds-first-ai-generated-foreign-minister/</guid>

					<description><![CDATA[Ukraine has embarked on a pioneering venture by introducing the world’s first ‘AI diplomat’. The country has developed an artificial intelligence (AI) generated spokesperson to be the face and voice of their Ministry of Foreign Affairs. The AI, named Victoria Shi, has been launched to announce updates on various fronts, on behalf of the Ukrainian [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Ukraine has embarked on a pioneering venture by introducing the world’s first ‘AI diplomat’. The country has developed an artificial intelligence (AI) generated spokesperson to be the face and voice of their Ministry of Foreign Affairs. The AI, named Victoria Shi, has been launched to announce updates on various fronts, on behalf of the Ukrainian […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/meet-victoria-shi-the-worlds-first-ai-generated-foreign-minister/">Meet Victoria Shi, the World’s First AI-Generated Foreign Minister</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Gemini Upgrade 2024: Focus on Boosting Power and Accessibility</title>
		<link>https://www.sawberries.com/2024/05/02/gemini-gets-upgrade-boosting-power-and-accessibility/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 11:02:17 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[data science]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Gemini]]></category>
		<category><![CDATA[google]]></category>
		<category><![CDATA[Google Gemini]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[News]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/gemini-gets-upgrade-boosting-power-and-accessibility/</guid>

					<description><![CDATA[This is exciting news for language enthusiasts and AI users worldwide! Gemini Upgrade is here! On April 30, 2024, the Gemini mobile app received a major update that expanded its reach and accessibility worldwide. This update breaks down language barriers, making Gemini an international AI experience. The Gemini app is now available in various languages, [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>This is exciting news for language enthusiasts and AI users worldwide! Gemini Upgrade is here! On April 30, 2024, the Gemini mobile app received a major update that expanded its reach and accessibility worldwide. This update breaks down language barriers, making Gemini an international AI experience. The Gemini app is now available in various languages, […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/gemini-gets-upgrade-boosting-power-and-accessibility/">Gemini Upgrade 2024: Focus on Boosting Power and Accessibility</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Meet India’s ChatGPT Rival – Hanooman GPT is Here!</title>
		<link>https://www.sawberries.com/2024/05/02/meet-indias-chatgpt-rival-hanooman-gpt-is-here/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 11:02:15 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[AI Tools]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Beginner]]></category>
		<category><![CDATA[ChatGPT]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Hanooman]]></category>
		<category><![CDATA[Krutrim AI]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Ola]]></category>
		<category><![CDATA[Reliance AI]]></category>
		<category><![CDATA[supertools]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/meet-indias-chatgpt-rival-hanooman-gpt-is-here/</guid>

					<description><![CDATA[Introduction It’s not Tuesday, but it’s still a Hanooman’s day. Finally, the SML-powered Hanooman GPT is here! India now has its own indigenous alternative to OpenAI’s viral ChatGPT model. Hanooman GPT is a series of open-source Indic large language models developed by the Indian Institute of Technology (IIT) Bombay in partnership with healthcare AI firm [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction It’s not Tuesday, but it’s still a Hanooman’s day. Finally, the SML-powered Hanooman GPT is here! India now has its own indigenous alternative to OpenAI’s viral ChatGPT model. Hanooman GPT is a series of open-source Indic large language models developed by the Indian Institute of Technology (IIT) Bombay in partnership with healthcare AI firm […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/meet-indias-chatgpt-rival-hanooman-gpt-is-here/">Meet India’s ChatGPT Rival – Hanooman GPT is Here!</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Natural language boosts LLM performance in coding, planning, and robotics</title>
		<link>https://www.sawberries.com/2024/05/02/natural-language-boosts-llm-performance-coding-planning-robotics-0501/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 07:25:27 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Brain and cognitive sciences]]></category>
		<category><![CDATA[Center for Brains Minds and Machines]]></category>
		<category><![CDATA[Computer Science and Artificial Intelligence Laboratory (CSAIL)]]></category>
		<category><![CDATA[Computer science and technology]]></category>
		<category><![CDATA[Computer vision]]></category>
		<category><![CDATA[Defense Advanced Research Projects Agency (DARPA)]]></category>
		<category><![CDATA[Department of Defense (DoD)]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Human-computer interaction]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT-IBM Watson AI Lab]]></category>
		<category><![CDATA[National Science Foundation (NSF)]]></category>
		<category><![CDATA[Natural language processing]]></category>
		<category><![CDATA[Programming]]></category>
		<category><![CDATA[programming languages]]></category>
		<category><![CDATA[Quest for Intelligence]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<category><![CDATA[School of Science]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/natural-language-boosts-llm-performance-coding-planning-robotics-0501/</guid>

					<description><![CDATA[Large language models (LLMs) are becoming increasingly useful for programming and robotics tasks, but for more complicated reasoning problems, the gap between these systems and humans looms large. Without the ability to learn new concepts like humans do, these systems fail to form good abstractions — essentially, high-level representations of complex concepts that skip less-important [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Large language models (LLMs) are becoming increasingly useful for programming and robotics tasks, but for more complicated reasoning problems, the gap between these systems and humans looms large. Without the ability to learn new concepts like humans do, these systems fail to form good abstractions — essentially, high-level representations of complex concepts that skip less-important details — and thus sputter when asked to do more sophisticated tasks.</p>
<p>Luckily, MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) researchers have found a treasure trove of abstractions within natural language. In three papers to be presented at the International Conference on Learning Representations this month, the group shows how our everyday words are a rich source of context for language models, helping them build better overarching representations for code synthesis, AI planning, and robotic navigation and manipulation.</p>
<p>The three separate frameworks build libraries of abstractions for their given task: <a href="https://arxiv.org/abs/2310.19791" target="_blank" rel="noopener">LILO</a> (library induction from language observations) can synthesize, compress, and document code; <a href="https://arxiv.org/abs/2312.08566" target="_blank" rel="noopener">Ada</a> (action domain acquisition) explores sequential decision-making for artificial intelligence agents; and <a href="https://arxiv.org/abs/2402.18759" target="_blank" rel="noopener">LGA</a> (language-guided abstraction) helps robots better understand their environments to develop more feasible plans. Each system is a neurosymbolic method, a type of AI that blends human-like neural networks and program-like logical components.</p>
<p><strong>LILO: A neurosymbolic framework that codes</strong></p>
<p>Large language models can be used to quickly write solutions to small-scale coding tasks, but cannot yet architect entire software libraries like the ones written by human software engineers. To take their software development capabilities further, AI models need to refactor (cut down and combine) code into libraries of succinct, readable, and reusable programs.</p>
<p>Refactoring tools like the previously developed MIT-led <a href="https://mlb2251.github.io/stitch_jul11.pdf" target="_blank" rel="noopener">Stitch</a> algorithm can automatically identify abstractions, so, in a nod to the Disney movie “Lilo &amp; Stitch,” CSAIL researchers combined these algorithmic refactoring approaches with LLMs. Their neurosymbolic method LILO uses a standard LLM to write code, then pairs it with Stitch to find abstractions that are comprehensively documented in a library.</p>
<p>LILO’s unique emphasis on natural language allows the system to do tasks that require human-like commonsense knowledge, such as identifying and removing all vowels from a string of code and drawing a snowflake. In both cases, the CSAIL system outperformed standalone LLMs, as well as a previous library learning algorithm from MIT called DreamCoder, indicating its ability to build a deeper understanding of the words within prompts. These encouraging results point to how LILO could assist with things like writing programs to manipulate documents like Excel spreadsheets, helping AI answer questions about visuals, and drawing 2D graphics.</p>
<p>“Language models prefer to work with functions that are named in natural language,” says Gabe Grand SM &#8217;23, an MIT PhD student in electrical engineering and computer science, CSAIL affiliate, and lead author on the research. “Our work creates more straightforward abstractions for language models and assigns natural language names and documentation to each one, leading to more interpretable code for programmers and improved system performance.”</p>
<p>When prompted on a programming task, LILO first uses an LLM to quickly propose solutions based on data it was trained on, and then the system slowly searches more exhaustively for outside solutions. Next, Stitch efficiently identifies common structures within the code and pulls out useful abstractions. These are then automatically named and documented by LILO, resulting in simplified programs that can be used by the system to solve more complex tasks.</p>
<p>The MIT framework writes programs in domain-specific programming languages, like Logo, a language developed at MIT in the 1970s to teach children about programming. Scaling up automated refactoring algorithms to handle more general programming languages like Python will be a focus for future research. Still, their work represents a step forward for how language models can facilitate increasingly elaborate coding activities.</p>
<p><strong>Ada: Natural language guides AI task planning</strong></p>
<p>Just like in programming, AI models that automate multi-step tasks in households and command-based video games lack abstractions. Imagine you’re cooking breakfast and ask your roommate to bring a hot egg to the table — they’ll intuitively abstract their background knowledge about cooking in your kitchen into a sequence of actions. In contrast, an LLM trained on similar information will still struggle to reason about what they need to build a flexible plan.</p>
<p>Named after the famed mathematician Ada Lovelace, who many consider the world’s first programmer, the CSAIL-led “Ada” framework makes headway on this issue by developing libraries of useful plans for virtual kitchen chores and gaming. The method trains on potential tasks and their natural language descriptions, then a language model proposes action abstractions from this dataset. A human operator scores and filters the best plans into a library, so that the best possible actions can be implemented into hierarchical plans for different tasks.</p>
<p>“Traditionally, large language models have struggled with more complex tasks because of problems like reasoning about abstractions,” says Ada lead researcher Lio Wong, an MIT graduate student in brain and cognitive sciences, CSAIL affiliate, and LILO coauthor. “But we can combine the tools that software engineers and roboticists use with LLMs to solve hard problems, such as decision-making in virtual environments.”</p>
<p>When the researchers incorporated the widely-used large language model GPT-4 into Ada, the system completed more tasks in a kitchen simulator and Mini Minecraft than the AI decision-making baseline “Code as Policies.” Ada used the background information hidden within natural language to understand how to place chilled wine in a cabinet and craft a bed. The results indicated a staggering 59 and 89 percent task accuracy improvement, respectively.</p>
<p>With this success, the researchers hope to generalize their work to real-world homes, with the hopes that Ada could assist with other household tasks and aid multiple robots in a kitchen. For now, its key limitation is that it uses a generic LLM, so the CSAIL team wants to apply a more powerful, fine-tuned language model that could assist with more extensive planning. Wong and her colleagues are also considering combining Ada with a robotic manipulation framework fresh out of CSAIL: LGA (language-guided abstraction).</p>
<p><strong>Language-guided abstraction: Representations for robotic tasks</strong></p>
<p>Andi Peng SM ’23, an MIT graduate student in electrical engineering and computer science and CSAIL affiliate, and her coauthors designed a method to help machines interpret their surroundings more like humans, cutting out unnecessary details in a complex environment like a factory or kitchen. Just like LILO and Ada, LGA has a novel focus on how natural language leads us to those better abstractions.</p>
<p>In these more unstructured environments, a robot will need some common sense about what it’s tasked with, even with basic training beforehand. Ask a robot to hand you a bowl, for instance, and the machine will need a general understanding of which features are important within its surroundings. From there, it can reason about how to give you the item you want. </p>
<p>In LGA’s case, humans first provide a pre-trained language model with a general task description using natural language, like “bring me my hat.” Then, the model translates this information into abstractions about the essential elements needed to perform this task. Finally, an imitation policy trained on a few demonstrations can implement these abstractions to guide a robot to grab the desired item.</p>
<p>Previous work required a person to take extensive notes on different manipulation tasks to pre-train a robot, which can be expensive. Remarkably, LGA guides language models to produce abstractions similar to those of a human annotator, but in less time. To illustrate this, LGA developed robotic policies to help Boston Dynamics’ Spot quadruped pick up fruits and throw drinks in a recycling bin. These experiments show how the MIT-developed method can scan the world and develop effective plans in unstructured environments, potentially guiding autonomous vehicles on the road and robots working in factories and kitchens.</p>
<p>“In robotics, a truth we often disregard is how much we need to refine our data to make a robot useful in the real world,” says Peng. “Beyond simply memorizing what’s in an image for training robots to perform tasks, we wanted to leverage computer vision and captioning models in conjunction with language. By producing text captions from what a robot sees, we show that language models can essentially build important world knowledge for a robot.”</p>
<p>The challenge for LGA is that some behaviors can’t be explained in language, making certain tasks underspecified. To expand how they represent features in an environment, Peng and her colleagues are considering incorporating multimodal visualization interfaces into their work. In the meantime, LGA provides a way for robots to gain a better feel for their surroundings when giving humans a helping hand. </p>
<p><strong>An “exciting frontier” in AI</strong></p>
<p>“Library learning represents one of the most exciting frontiers in artificial intelligence, offering a path towards discovering and reasoning over compositional abstractions,” says assistant professor at the University of Wisconsin-Madison Robert Hawkins, who was not involved with the papers. Hawkins notes that previous techniques exploring this subject have been “too computationally expensive to use at scale” and have an issue with the lambdas, or keywords used to describe new functions in many languages, that they generate. “They tend to produce opaque &#8216;lambda salads,&#8217; big piles of hard-to-interpret functions. These recent papers demonstrate a compelling way forward by placing large language models in an interactive loop with symbolic search, compression, and planning algorithms. This work enables the rapid acquisition of more interpretable and adaptive libraries for the task at hand.”</p>
<p>By building libraries of high-quality code abstractions using natural language, the three neurosymbolic methods make it easier for language models to tackle more elaborate problems and environments in the future. This deeper understanding of the precise keywords within a prompt presents a path forward in developing more human-like AI models.</p>
<p>MIT CSAIL members are senior authors for each paper: Joshua Tenenbaum, a professor of brain and cognitive sciences, for both LILO and Ada; Julie Shah, head of the Department of Aeronautics and Astronautics, for LGA; and Jacob Andreas, associate professor of electrical engineering and computer science, for all three. The additional MIT authors are all PhD students: Maddy Bowers and Theo X. Olausson for LILO, Jiayuan Mao and Pratyusha Sharma for Ada, and Belinda Z. Li for LGA. Muxin Liu of Harvey Mudd College was a coauthor on LILO; Zachary Siegel of Princeton University, Jaihai Feng of the University of California at Berkeley, and Noa Korneev of Microsoft were coauthors on Ada; and Ilia Sucholutsky, Theodore R. Sumers, and Thomas L. Griffiths of Princeton were coauthors on LGA. </p>
<p>LILO and Ada were supported, in part, by ​​MIT Quest for Intelligence, the MIT-IBM Watson AI Lab, Intel, U.S. Air Force Office of Scientific Research, the U.S. Defense Advanced Research Projects Agency, and the U.S. Office of Naval Research, with the latter project also receiving funding from the Center for Brains, Minds and Machines. LGA received funding from the U.S. National Science Foundation, Open Philanthropy, the Natural Sciences and Engineering Research Council of Canada, and the U.S. Department of Defense.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>8 Gemini Free Courses by Google to master it </title>
		<link>https://www.sawberries.com/2024/05/02/gemini-free-courses-by-google/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 07:25:24 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Courses]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Gemini]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[google]]></category>
		<category><![CDATA[Google Gemini]]></category>
		<category><![CDATA[Listicle]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/gemini-free-courses-by-google/</guid>

					<description><![CDATA[Introduction Google Gemini is one of the most popular chatbots around. And guess what? Google offers eight free lessons to help you become a Gemini pro! Whether you’re a tech enthusiast or a complete beginner, these courses cater to a wide range of learners, equipping you with the skills to leverage Gemini’s capabilities and unlock [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction Google Gemini is one of the most popular chatbots around. And guess what? Google offers eight free lessons to help you become a Gemini pro! Whether you’re a tech enthusiast or a complete beginner, these courses cater to a wide range of learners, equipping you with the skills to leverage Gemini’s capabilities and unlock […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/gemini-free-courses-by-google/">8 Gemini Free Courses by Google to master it </a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Build a Winning Dream 11 Team Using Python and AI</title>
		<link>https://www.sawberries.com/2024/05/02/build-a-winning-dream-team-using-python-and-ai/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 07:25:23 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Beginner]]></category>
		<category><![CDATA[Dream 11]]></category>
		<category><![CDATA[fantasy games]]></category>
		<category><![CDATA[fantasy sports]]></category>
		<category><![CDATA[games]]></category>
		<category><![CDATA[Guide]]></category>
		<category><![CDATA[india]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[My Circle]]></category>
		<category><![CDATA[Prediction]]></category>
		<category><![CDATA[Python]]></category>
		<category><![CDATA[team building]]></category>
		<category><![CDATA[website]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/build-a-winning-dream-team-using-python-and-ai/</guid>

					<description><![CDATA[Introduction The exponential rise of IPL in India has correlatively resulted in the growth of fantasy cricket in the country. In recent years, we have seen more and more people playing on platforms like Dream 11, My Circle, etc. every day. Dream11 is a fantasy sports app where you can create your fantasy team for [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction The exponential rise of IPL in India has correlatively resulted in the growth of fantasy cricket in the country. In recent years, we have seen more and more people playing on platforms like Dream 11, My Circle, etc. every day. Dream11 is a fantasy sports app where you can create your fantasy team for […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/build-a-winning-dream-team-using-python-and-ai/">Build a Winning Dream 11 Team Using Python and AI</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Phi 3 – Small Yet Powerful Models from Microsoft</title>
		<link>https://www.sawberries.com/2024/05/01/phi-3-small-yet-powerful-models-from-microsoft/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Wed, 01 May 2024 15:45:28 +0000</pubDate>
				<category><![CDATA[Advanced]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[blogathon]]></category>
		<category><![CDATA[language models]]></category>
		<category><![CDATA[Large Language Models]]></category>
		<category><![CDATA[LLM]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Models]]></category>
		<category><![CDATA[questions]]></category>
		<category><![CDATA[Supervised]]></category>
		<category><![CDATA[tokenizer]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/01/phi-3-small-yet-powerful-models-from-microsoft/</guid>

					<description><![CDATA[Introduction The Phi model from Microsoft has been at the forefront of many open-source Large Language Models. Phi architecture has led to all the popular small open-source models that we see today which include TPhixtral, Phi-DPO, and others. Their Phi Family has taken the LLM architecture a step forward with the introduction of Small Language [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction The Phi model from Microsoft has been at the forefront of many open-source Large Language Models. Phi architecture has led to all the popular small open-source models that we see today which include TPhixtral, Phi-DPO, and others. Their Phi Family has taken the LLM architecture a step forward with the introduction of Small Language […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/phi-3-small-yet-powerful-models-from-microsoft/">Phi 3 – Small Yet Powerful Models from Microsoft</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
