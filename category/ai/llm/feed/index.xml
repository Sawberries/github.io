<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>LLM &#8211; sawberries</title>
	<atom:link href="http://localhost/sawberries/category/ai/llm/feed/?simply_static_page=1093025" rel="self" type="application/rss+xml" />
	<link>https://www.sawberries.com</link>
	<description>www.sawberry.com site</description>
	<lastBuildDate>Sun, 05 May 2024 09:01:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.2</generator>

<image>
	<url>https://www.sawberries.com/wp-content/uploads/2024/04/cropped-DALL·E-2024-04-26-12.21.04-A-512x512-favicon-design-that-incorporates-a-playful-twist-on-the-concept-of-a-strawberry-symbolizing-connections-between-people.-The-strawberry-shou-32x32.webp</url>
	<title>LLM &#8211; sawberries</title>
	<link>https://www.sawberries.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Paramanu-Ganita: A New Mathematical Model that Outperforms LLaMa, Falcon, and PaLM</title>
		<link>https://www.sawberries.com/2024/05/05/paramanu-ganita-a-new-mathematical-model-that-outperforms-llama-falcon-and-palm/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Sun, 05 May 2024 09:01:13 +0000</pubDate>
				<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Design]]></category>
		<category><![CDATA[efficiency]]></category>
		<category><![CDATA[Gyan AI]]></category>
		<category><![CDATA[Intermediate]]></category>
		<category><![CDATA[language models]]></category>
		<category><![CDATA[Large Language Models]]></category>
		<category><![CDATA[LLM]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[Mathematics]]></category>
		<category><![CDATA[Maths]]></category>
		<category><![CDATA[Models]]></category>
		<category><![CDATA[Paramanu-Ganita]]></category>
		<category><![CDATA[small language models]]></category>
		<category><![CDATA[training]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/05/paramanu-ganita-a-new-mathematical-model-that-outperforms-llama-falcon-and-palm/</guid>

					<description><![CDATA[Introduction Large language models (LLMs) have dramatically reshaped computational mathematics. These advanced AI systems, designed to process and mimic human-like text, are now pushing boundaries in mathematical fields. Their ability to understand and manipulate complex concepts has made them invaluable in research and development. Among these innovations stands Paramanu-Ganita, a creation of Gyan AI Research. [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction Large language models (LLMs) have dramatically reshaped computational mathematics. These advanced AI systems, designed to process and mimic human-like text, are now pushing boundaries in mathematical fields. Their ability to understand and manipulate complex concepts has made them invaluable in research and development. Among these innovations stands Paramanu-Ganita, a creation of Gyan AI Research. […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/paramanu-ganita-a-new-mathematical-model-that-outperforms-llama-falcon-and-palm/">Paramanu-Ganita: A New Mathematical Model that Outperforms LLaMa, Falcon, and PaLM</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Finetuning Llama 3 with Odds Ratio Preference Optimization</title>
		<link>https://www.sawberries.com/2024/05/02/finetuning-llama-3-with-odds-ratio-preference-optimization/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 11:02:18 +0000</pubDate>
				<category><![CDATA[Advanced]]></category>
		<category><![CDATA[blogathon]]></category>
		<category><![CDATA[dataset]]></category>
		<category><![CDATA[fine tuning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Guide]]></category>
		<category><![CDATA[HuggingFace]]></category>
		<category><![CDATA[Kaggle]]></category>
		<category><![CDATA[language models]]></category>
		<category><![CDATA[Large Language Models]]></category>
		<category><![CDATA[LLM]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[Models]]></category>
		<category><![CDATA[optimization]]></category>
		<category><![CDATA[PyTorch]]></category>
		<category><![CDATA[Supervised]]></category>
		<category><![CDATA[time]]></category>
		<category><![CDATA[training]]></category>
		<category><![CDATA[Unsupervised]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/finetuning-llama-3-with-odds-ratio-preference-optimization/</guid>

					<description><![CDATA[Introduction Large Language Models are often trained rather than built, requiring multiple steps to perform well. These steps, including Supervised Fine Tuning (SFT) and Preference Alignment, are crucial for learning new things and aligning with human responses. However, each step takes a significant amount of time and computing resources. One solution is the Odd Ratio [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction Large Language Models are often trained rather than built, requiring multiple steps to perform well. These steps, including Supervised Fine Tuning (SFT) and Preference Alignment, are crucial for learning new things and aligning with human responses. However, each step takes a significant amount of time and computing resources. One solution is the Odd Ratio […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/finetuning-llama-3-with-odds-ratio-preference-optimization/">Finetuning Llama 3 with Odds Ratio Preference Optimization</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Phi 3 – Small Yet Powerful Models from Microsoft</title>
		<link>https://www.sawberries.com/2024/05/01/phi-3-small-yet-powerful-models-from-microsoft/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Wed, 01 May 2024 15:45:28 +0000</pubDate>
				<category><![CDATA[Advanced]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[blogathon]]></category>
		<category><![CDATA[language models]]></category>
		<category><![CDATA[Large Language Models]]></category>
		<category><![CDATA[LLM]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Models]]></category>
		<category><![CDATA[questions]]></category>
		<category><![CDATA[Supervised]]></category>
		<category><![CDATA[tokenizer]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/01/phi-3-small-yet-powerful-models-from-microsoft/</guid>

					<description><![CDATA[Introduction The Phi model from Microsoft has been at the forefront of many open-source Large Language Models. Phi architecture has led to all the popular small open-source models that we see today which include TPhixtral, Phi-DPO, and others. Their Phi Family has taken the LLM architecture a step forward with the introduction of Small Language [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction The Phi model from Microsoft has been at the forefront of many open-source Large Language Models. Phi architecture has led to all the popular small open-source models that we see today which include TPhixtral, Phi-DPO, and others. Their Phi Family has taken the LLM architecture a step forward with the introduction of Small Language […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/05/phi-3-small-yet-powerful-models-from-microsoft/">Phi 3 – Small Yet Powerful Models from Microsoft</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>RAG and Streamlit Chatbot: Chat with Documents Using LLM</title>
		<link>https://www.sawberries.com/2024/04/30/rag-and-streamlit-chatbot-chat-with-documents-using-llm/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Tue, 30 Apr 2024 12:01:35 +0000</pubDate>
				<category><![CDATA[Advanced]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[chatbot]]></category>
		<category><![CDATA[ChatGPT]]></category>
		<category><![CDATA[Classification]]></category>
		<category><![CDATA[documents]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Guide]]></category>
		<category><![CDATA[Langchain]]></category>
		<category><![CDATA[large language model]]></category>
		<category><![CDATA[Large Language Models]]></category>
		<category><![CDATA[LLM]]></category>
		<category><![CDATA[LLMs]]></category>
		<category><![CDATA[strealit]]></category>
		<category><![CDATA[Streamlit]]></category>
		<category><![CDATA[vector]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/30/rag-and-streamlit-chatbot-chat-with-documents-using-llm/</guid>

					<description><![CDATA[Introduction This article aims to create an AI-powered RAG and Streamlit chatbot that can answer users questions based on custom documents. Users can upload documents, and the chatbot can answer questions by referring to those documents. The interface will be generated using Streamlit, and the chatbot will use open-source Large Language Model (LLM) models, making [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Introduction This article aims to create an AI-powered RAG and Streamlit chatbot that can answer users questions based on custom documents. Users can upload documents, and the chatbot can answer questions by referring to those documents. The interface will be generated using Streamlit, and the chatbot will use open-source Large Language Model (LLM) models, making […]</p>
<p>The post <a href="https://www.analyticsvidhya.com/blog/2024/04/rag-and-streamlit-chatbot-chat-with-documents-using-llm/">RAG and Streamlit Chatbot: Chat with Documents Using LLM</a> appeared first on <a href="https://www.analyticsvidhya.com/">Analytics Vidhya</a>.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
