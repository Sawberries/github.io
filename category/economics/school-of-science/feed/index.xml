<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>School of Science &#8211; sawberries</title>
	<atom:link href="http://localhost/sawberries/category/economics/school-of-science/feed/?simply_static_page=1688591" rel="self" type="application/rss+xml" />
	<link>https://www.sawberries.com</link>
	<description>www.sawberry.com site</description>
	<lastBuildDate>Thu, 16 May 2024 07:55:49 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.3</generator>

<image>
	<url>https://www.sawberries.com/wp-content/uploads/2024/04/cropped-DALL·E-2024-04-26-12.21.04-A-512x512-favicon-design-that-incorporates-a-playful-twist-on-the-concept-of-a-strawberry-symbolizing-connections-between-people.-The-strawberry-shou-32x32.webp</url>
	<title>School of Science &#8211; sawberries</title>
	<link>https://www.sawberries.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>John Joannopoulos receives 2024-2025 Killian Award</title>
		<link>https://www.sawberries.com/2024/05/16/john-joannopoulos-receives-killian-award-0515/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 16 May 2024 07:55:49 +0000</pubDate>
				<category><![CDATA[Awards, honors and fellowships]]></category>
		<category><![CDATA[Faculty]]></category>
		<category><![CDATA[Institute for Soldier Nanotechnologies]]></category>
		<category><![CDATA[nano]]></category>
		<category><![CDATA[Nanoscience and nanotechnology]]></category>
		<category><![CDATA[Photonics]]></category>
		<category><![CDATA[Physics]]></category>
		<category><![CDATA[School of Science]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/16/john-joannopoulos-receives-killian-award-0515/</guid>

					<description><![CDATA[John Joannopoulos, an innovator and mentor in the fields of theoretical condensed matter physics and nanophotonics, has been named the recipient of the 2024-2025 James R. Killian Jr. Faculty Achievement Award. Joannopoulos is the Francis Wright Davis Professor of Physics and director of MIT’s Institute for Soldier Nanotechnologies. He has been a member of the [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>John Joannopoulos, an innovator and mentor in the fields of theoretical condensed matter physics and nanophotonics, has been named the recipient of the 2024-2025 James R. Killian Jr. Faculty Achievement Award.</p>
<p>Joannopoulos is the Francis Wright Davis Professor of Physics and director of MIT’s Institute for Soldier Nanotechnologies. He has been a member of the MIT faculty for 50 years.</p>
<p>“Professor Joannopoulos’s profound and lasting impact on the field of theoretical condensed matter physics finds its roots in his pioneering work in harnessing ab initio physics to elucidate the behavior of materials at the atomic level,” states the award citation, which was announced at today’s faculty meeting by Roger White, chair of the Killian Award Selection Committee and professor of philosophy at MIT. “His seminal research in the development of photonic crystals has revolutionized understanding of light-matter interactions, laying the groundwork for transformative advancements in diverse fields ranging from telecommunications to biomedical engineering.”</p>
<p>The award also honors Joannopoulos’ service as a “legendary mentor to generations of students, inspiring them to achieve excellence in science while at the same time facilitating the practical benefit to society through entrepreneurship.”</p>
<p>The Killian Award was established in 1971 to recognize outstanding professional contributions by MIT faculty members. It is the highest honor that the faculty can give to one of its members.</p>
<p>“I have to tell you, it was a complete and utter surprise,” Joannopoulos told <em>MIT News</em> shortly after he received word of the award. “I didn’t expect it at all, and was extremely flattered, honored, and moved by it, frankly.”</p>
<p>Joannopoulous has spent his entire professional career at MIT. He came to the Institute in 1974, directly after receiving his PhD in physics at the University of California at Berkeley, where he also earned his bachelor’s degree. Starting out as an assistant professor in MIT’s Department of Physics, he quickly set up a research program focused on theoretical condensed matter physics.</p>
<p>Over the first half of his MIT career, Joannopoulos worked to elucidate the fundamental nature of the electronic, vibrational, and optical structure of crystalline and amorphous bulk solids, their surfaces, interfaces, and defects. He and his students developed numerous theoretical methods to enable tractable and accurate calculations of these complex systems.</p>
<p>In the 1990s, his work with microscopic material systems expanded to a new class of materials, called photonic crystals — materials that could be engineered at the micro- and nanoscale to manipulate light in ways that impart surprising and exotic optical qualities to the material as a whole.</p>
<p>“I saw that you could create photonic crystals with defects that can affect the properties of photons, in much the same way that defects in a semiconductor affect the properties of electrons,” Joannopoulos says. “So I started working in this area to try and explore what anomalous light phenomena can we discover using this approach?”</p>
<p>Among his various breakthroughs in the field was the realization of a <a href="https://news.mit.edu/1998/mirror-1209" target="_blank" rel="noopener">“perfect dielectic mirror”</a> — a multilayered optical device that reflects light from all angles as normal metallic mirrors do, and that can also be tuned to reflect and trap light at specific frequencies. He and his colleagues saw potential for the mirror to be made into a hollow fiber that could serve as a highly effective optical conduit, for use in a wide range of applications. To further advance the technology, he and his colleagues launched a startup, which has since developed the technology into a flexible, fiber-optic “surgical scalpel.”</p>
<p>Throughout his career, Joannopoulos has helped to launch numerous startups and photonics-based technologies.</p>
<p>“His ability to bridge the gap between academia and industry has not only advanced scientific knowledge but also led to the creation of dozens of new companies, thousands of jobs, and groundbreaking products that continue to benefit society to this day,” the award citation states.</p>
<p>In 2006, Joannopoulos accepted the position as director of MIT’s Institute for Soldier Nanotechnologies (ISN), a collaboration between MIT researchers, industry partners, and military defense experts, who seek innovations to protect and enhance soldiers’ survivability in the field. In his role as ISN head, Joannopoulos has worked across MIT, making connections and supporting new projects with researchers specializing in fields far from his own.</p>
<p>“I get a chance to explore and learn fascinating new things,” says Joannopoulos, who is currently overseeing projects related to hyperspectral imaging, smart and responsive fabrics, and nanodrug delivery. “I love that aspect of really getting to understand what people in other fields are doing. And they’re doing great work across many, many different fields.”</p>
<p>Throughout his career at MIT, Joannopoulos has been especially inspired and motivated by his students, many of whom have gone on to found companies, lead top academic and research institutions, and make significant contributions to their respective fields, including one student who was awarded the Nobel Prize in Physics in 1998.</p>
<p>“One’s proudest moments are the successes of one’s students, and in that regard, I’ve been extremely lucky to have had truly exceptional students over the years,” Joannopolous says.</p>
<p>His many contributions to academia and industry have earned Joannopoulos numerous honors and awards, including his election to both the National Academy of Sciences and the American Academy of Arts and Sciences. He is also a fellow of both the American Physical Society and the American Association for the Advancement of Science.</p>
<p>“The Selection Committee is delighted to have this opportunity to honor Professor John Joannopoulos: a visionary scientist, a beloved mentor, a great believer in the goodness of people, and a leader whose contributions to MIT and the broader scientific community are immeasurable,” the award citation concludes.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Scientists use generative AI to answer complex questions in physics</title>
		<link>https://www.sawberries.com/2024/05/16/scientists-use-generative-ai-complex-questions-physics-0516/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 16 May 2024 07:55:44 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Computer modeling]]></category>
		<category><![CDATA[Computer Science and Artificial Intelligence Laboratory (CSAIL)]]></category>
		<category><![CDATA[Computer science and technology]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Mathematics]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[Physics]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<category><![CDATA[School of Science]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/16/scientists-use-generative-ai-complex-questions-physics-0516/</guid>

					<description><![CDATA[When water freezes, it transitions from a liquid phase to a solid phase, resulting in a drastic change in properties like density and volume. Phase transitions in water are so common most of us probably don’t even think about them, but phase transitions in novel materials or complex physical systems are an important area of [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>When water freezes, it transitions from a liquid phase to a solid phase, resulting in a drastic change in properties like density and volume. Phase transitions in water are so common most of us probably don’t even think about them, but phase transitions in novel materials or complex physical systems are an important area of study.</p>
<p>To fully understand these systems, scientists must be able to recognize phases and detect the transitions between. But how to quantify phase changes in an unknown system is often unclear, especially when data are scarce.</p>
<p>Researchers from MIT and the University of Basel in Switzerland applied generative artificial intelligence models to this problem, developing a new machine-learning framework that can automatically map out phase diagrams for novel physical systems.</p>
<p>Their physics-informed machine-learning approach is more efficient than laborious, manual techniques which rely on theoretical expertise. Importantly, because their approach leverages generative models, it does not require huge, labeled training datasets used in other machine-learning techniques.</p>
<p>Such a framework could help scientists investigate the thermodynamic properties of novel materials or detect entanglement in quantum systems, for instance. Ultimately, this technique could make it possible for scientists to discover unknown phases of matter autonomously.</p>
<p>“If you have a new system with fully unknown properties, how would you choose which observable quantity to study? The hope, at least with data-driven tools, is that you could scan large new systems in an automated way, and it will point you to important changes in the system. This might be a tool in the pipeline of automated scientific discovery of new, exotic properties of phases,” says Frank Schäfer, a postdoc in the Julia Lab in the Computer Science and Artificial Intelligence Laboratory (CSAIL) and co-author of a paper on this approach.</p>
<p>Joining Schäfer on the paper are first author Julian Arnold, a graduate student at the University of Basel; Alan Edelman, applied mathematics professor in the Department of Mathematics and leader of the Julia Lab; and senior author Christoph Bruder, professor in the Department of Physics at the University of Basel. The research is <a href="https://doi.org/10.1103/PhysRevLett.132.207301" target="_blank" rel="noopener">published today</a> in <em>Physical Review Letters.</em></p>
<p><strong>Detecting phase transitions using AI</strong></p>
<p>While water transitioning to ice might be among the most obvious examples of a phase change, more exotic phase changes, like when a material transitions from being a normal conductor to a superconductor, are of keen interest to scientists.</p>
<p>These transitions can be detected by identifying an “order parameter,” a quantity that is important and expected to change. For instance, water freezes and transitions to a solid phase (ice) when its temperature drops below 0 degrees Celsius. In this case, an appropriate order parameter could be defined in terms of the proportion of water molecules that are part of the crystalline lattice versus those that remain in a disordered state.</p>
<p>In the past, researchers have relied on physics expertise to build phase diagrams manually, drawing on theoretical understanding to know which order parameters are important. Not only is this tedious for complex systems, and perhaps impossible for unknown systems with new behaviors, but it also introduces human bias into the solution.</p>
<p>More recently, researchers have begun using machine learning to build discriminative classifiers that can solve this task by learning to classify a measurement statistic as coming from a particular phase of the physical system, the same way such models classify an image as a cat or dog.</p>
<p>The MIT researchers demonstrated how generative models can be used to solve this classification task much more efficiently, and in a physics-informed manner.</p>
<p>The <a href="https://julia.mit.edu/" target="_blank" rel="noopener">Julia Programming Language</a>, a popular language for scientific computing that is also used in MIT’s introductory linear algebra classes, offers many tools that make it invaluable for constructing such generative models, Schäfer adds.</p>
<p>Generative models, like those that underlie ChatGPT and Dall-E, typically work by estimating the probability distribution of some data, which they use to generate new data points that fit the distribution (such as new cat images that are similar to existing cat images).</p>
<p>However, when simulations of a physical system using tried-and-true scientific techniques are available, researchers get a model of its probability distribution for free. This distribution describes the measurement statistics of the physical system.</p>
<p><strong>A more knowledgeable model</strong></p>
<p>The MIT team’s insight is that this probability distribution also defines a generative model upon which a classifier can be constructed. They plug the generative model into standard statistical formulas to directly construct a classifier instead of learning it from samples, as was done with discriminative approaches.</p>
<p>“This is a really nice way of incorporating something you know about your physical system deep inside your machine-learning scheme. It goes far beyond just performing feature engineering on your data samples or simple inductive biases,” Schäfer says.</p>
<p>This generative classifier can determine what phase the system is in given some parameter, like temperature or pressure. And because the researchers directly approximate the probability distributions underlying measurements from the physical system, the classifier has system knowledge.</p>
<p>This enables their method to perform better than other machine-learning techniques. And because it can work automatically without the need for extensive training, their approach significantly enhances the computational efficiency of identifying phase transitions.</p>
<p>At the end of the day, similar to how one might ask ChatGPT to solve a math problem, the researchers can ask the generative classifier questions like “does this sample belong to phase I or phase II?” or “was this sample generated at high temperature or low temperature?”</p>
<p>Scientists could also use this approach to solve different binary classification tasks in physical systems, possibly to detect entanglement in quantum systems (Is the state entangled or not?) or determine whether theory A or B is best suited to solve a particular problem. They could also use this approach to better understand and improve large language models like ChatGPT by identifying how certain parameters should be tuned so the chatbot gives the best outputs.</p>
<p>In the future, the researchers also want to study theoretical guarantees regarding how many measurements they would need to effectively detect phase transitions and estimate the amount of computation that would require.</p>
<p>This work was funded, in part, by the Swiss National Science Foundation, the MIT-Switzerland Lockheed Martin Seed Fund, and MIT International Science and Technology Initiatives.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>President Sally Kornbluth and OpenAI CEO Sam Altman discuss the future of AI</title>
		<link>https://www.sawberries.com/2024/05/06/president-sally-kornbluth-openai-ceo-sam-altman-discuss-future-ai-0506/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Mon, 06 May 2024 15:01:15 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Business and management]]></category>
		<category><![CDATA[Careers]]></category>
		<category><![CDATA[Community]]></category>
		<category><![CDATA[Ethics]]></category>
		<category><![CDATA[History of science]]></category>
		<category><![CDATA[Human-computer interaction]]></category>
		<category><![CDATA[Innovation and Entrepreneurship (I&E)]]></category>
		<category><![CDATA[Invention]]></category>
		<category><![CDATA[Labor and jobs]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT Sloan School of Management]]></category>
		<category><![CDATA[President Sally Kornbluth]]></category>
		<category><![CDATA[School of Architecture and Planning]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<category><![CDATA[School of Humanities Arts and Social Sciences]]></category>
		<category><![CDATA[School of Science]]></category>
		<category><![CDATA[Special events and guest speakers]]></category>
		<category><![CDATA[Sustainability]]></category>
		<category><![CDATA[Technology and society]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/06/president-sally-kornbluth-openai-ceo-sam-altman-discuss-future-ai-0506/</guid>

					<description><![CDATA[How is the field of artificial intelligence evolving and what does it mean for the future of work, education, and humanity? MIT President Sally Kornbluth and OpenAI CEO Sam Altman covered all that and more in a wide-ranging discussion on MIT’s campus May 2. The success of OpenAI’s ChatGPT large language models has helped spur [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>How is the field of artificial intelligence evolving and what does it mean for the future of work, education, and humanity? MIT President Sally Kornbluth and OpenAI CEO Sam Altman covered all that and more in a wide-ranging discussion on MIT’s campus May 2.</p>
<p>The success of OpenAI’s ChatGPT large language models has helped spur a wave of investment and innovation in the field of artificial intelligence. ChatGPT-3.5 became the fastest-growing consumer software application in history after its release at the end of 2022, with hundreds of millions of people using the tool. Since then, OpenAI has also demonstrated AI-driven image-, audio-, and video-generation products and partnered with Microsoft.</p>
<p>The event, which took place in a packed Kresge Auditorium, captured the excitement of the moment around AI, with an eye toward what’s next.</p>
<p>“I think most of us remember the first time we saw ChatGPT and were like, ‘Oh my god, that is so cool!’” Kornbluth said. “Now we’re trying to figure out what the next generation of all this is going to be.”</p>
<p>For his part, Altman welcomes the high expectations around his company and the field of artificial intelligence more broadly.</p>
<p>“I think it’s awesome that for two weeks, everybody was freaking out about ChatGPT-4, and then by the third week, everyone was like, ‘Come on, where’s GPT-5?’” Altman said. “I think that says something legitimately great about human expectation and striving and why we all have to [be working to] make things better.”</p>
<p><strong>The problems with AI</strong></p>
<p>Early on in their discussion, Kornbluth and Altman discussed the many ethical dilemmas posed by AI.</p>
<p>“I think we’ve made surprisingly good progress around how to align a system around a set of values,” Altman said. “As much as people like to say ‘You can’t use these things because they’re spewing toxic waste all the time,’ GPT-4 behaves kind of the way you want it to, and we’re able to get it to follow a given set of values, not perfectly well, but better than I expected by this point.”</p>
<p>Altman also pointed out that people don’t agree on exactly how an AI system should behave in many situations, complicating efforts to create a universal code of conduct.</p>
<p>“How do we decide what values a system should have?” Altman asked. “How do we decide what a system should do? How much does society define boundaries versus trusting the user with these tools? Not everyone will use them the way we like, but that’s just kind of the case with tools. I think it’s important to give people a lot of control … but there are some things a system just shouldn’t do, and we’ll have to collectively negotiate what those are.”</p>
<p>Kornbluth agreed doing things like eradicating bias in AI systems will be difficult.</p>
<p>“It’s interesting to think about whether or not we can make models less biased than we are as human beings,” she said.</p>
<p>Kornbluth also brought up privacy concerns associated with the vast amounts of data needed to train today’s large language models. Altman said society has been grappling with those concerns since the dawn of the internet, but AI is making such considerations more complex and higher-stakes. He also sees entirely new questions raised by the prospect of powerful AI systems.</p>
<p>“How are we going to navigate the privacy versus utility versus safety tradeoffs?” Altman asked. “Where we all individually decide to set those tradeoffs, and the advantages that will be possible if someone lets the system be trained on their entire life, is a new thing for society to navigate. I don’t know what the answers will be.”</p>
<p>For both privacy and energy consumption concerns surrounding AI, Altman said he believes progress in future versions of AI models will help.</p>
<p>&#8220;What we want out of GPT-5 or 6 or whatever is for it to be the best reasoning engine possible,” Altman said. “It is true that right now, the only way we’re able to do that is by training it on tons and tons of data. In that process, it’s learning something about how to do very, very limited reasoning or cognition or whatever you want to call it. But the fact that it can memorize data, or the fact that it’s storing data at all in its parameter space, I think we&#8217;ll look back and say, ‘That was kind of a weird waste of resources.’ I assume at some point, we’ll figure out how to separate the reasoning engine from the need for tons of data or storing the data in [the model], and be able to treat them as separate things.”</p>
<p>Kornbluth also asked about how AI might lead to job displacement.</p>
<p>“One of the things that annoys me most about people who work on AI is when they stand up with a straight face and say, ‘This will never cause any job elimination. This is just an additive thing. This is just all going to be great,’” Altman said. “This is going to eliminate a lot of current jobs, and this is going to change the way that a lot of current jobs function, and this is going to create entirely new jobs. That always happens with technology.&#8221;</p>
<p><strong>The promise of AI</strong></p>
<p>Altman believes progress in AI will make grappling with all of the field’s current problems worth it.</p>
<p>“If we spent 1 percent of the world’s electricity training a powerful AI, and that AI helped us figure out how to get to non-carbon-based energy or make deep carbon capture better, that would be a massive win,” Altman said.</p>
<p>He also said the application of AI he’s most interested in is scientific discovery.</p>
<p>“I believe [scientific discovery] is the core engine of human progress and that it is the only way we drive sustainable economic growth,” Altman said. “People aren’t content with GPT-4. They want things to get better. Everyone wants life more and better and faster, and science is how we get there.”</p>
<p>Kornbluth also asked Altman for his advice for students thinking about their careers. He urged students not to limit themselves.</p>
<p>“The most important lesson to learn early on in your career is that you can kind of figure anything out, and no one has all of the answers when they start out,” Altman said. “You just sort of stumble your way through, have a fast iteration speed, and try to drift toward the most interesting problems to you, and be around the most impressive people and have this trust that you’ll successfully iterate to the right thing. &#8230; You can do more than you think, faster than you think.”</p>
<p>The advice was part of a broader message Altman had about staying optimistic and working to create a better future.</p>
<p>“The way we are teaching our young people that the world is totally screwed and that it’s hopeless to try to solve problems, that all we can do is sit in our bedrooms in the dark and think about how awful we are, is a really deeply unproductive streak,” Altman said. “I hope MIT is different than a lot of other college campuses. I assume it is. But you all need to make it part of your life mission to fight against this. Prosperity, abundance, a better life next year, a better life for our children. That is the only path forward. That is the only way to have a functioning society &#8230; and the anti-progress streak, the anti ‘people deserve a great life’ streak, is something I hope you all fight against.”</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Physicists arrange atoms in extremely close proximity</title>
		<link>https://www.sawberries.com/2024/05/03/physicists-arrange-atoms-extremely-close-proximity-0502/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Fri, 03 May 2024 00:01:05 +0000</pubDate>
				<category><![CDATA[Department of Defense (DoD)]]></category>
		<category><![CDATA[Light]]></category>
		<category><![CDATA[nano]]></category>
		<category><![CDATA[Nanoscience and nanotechnology]]></category>
		<category><![CDATA[National Science Foundation (NSF)]]></category>
		<category><![CDATA[Physics]]></category>
		<category><![CDATA[Quantum computing]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Research Laboratory of Electronics]]></category>
		<category><![CDATA[School of Science]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/03/physicists-arrange-atoms-extremely-close-proximity-0502/</guid>

					<description><![CDATA[Proximity is key for many quantum phenomena, as interactions between atoms are stronger when the particles are close. In many quantum simulators, scientists arrange atoms as close together as possible to explore exotic states of matter and build new quantum materials. They typically do this by cooling the atoms to a stand-still, then using laser [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Proximity is key for many quantum phenomena, as interactions between atoms are stronger when the particles are close. In many quantum simulators, scientists arrange atoms as close together as possible to explore exotic states of matter and build new quantum materials.</p>
<p>They typically do this by cooling the atoms to a stand-still, then using laser light to position the particles as close as 500 nanometers apart — a limit that is set by the wavelength of light. Now, MIT physicists have developed a technique that allows them to arrange atoms in much closer proximity, down to a mere 50 nanometers. For context, a red blood cell is about 1,000 nanometers wide.</p>
<p>The physicists demonstrated the new approach in experiments with dysprosium, which is the most magnetic atom in nature. They used the new approach to manipulate two layers of dysprosium atoms, and positioned the layers precisely 50 nanometers apart. At this extreme proximity, the magnetic interactions were 1,000 times stronger than if the layers were separated by 500 nanometers.</p>
<p>What’s more, the scientists were able to measure two new effects caused by the atoms’ proximity. Their enhanced magnetic forces caused “thermalization,” or the transfer of heat from one layer to another, as well as synchronized oscillations between layers. These effects petered out as the layers were spaced farther apart.</p>
<p>“We have gone from positioning atoms from 500 nanometers to 50 nanometers apart, and there is a lot you can do with this,” says Wolfgang Ketterle, the John D. MacArthur Professor of Physics at MIT. “At 50 nanometers, the behavior of atoms is so much different that we’re really entering a new regime here.”</p>
<p>Ketterle and his colleagues say the new approach can be applied to many other atoms to study quantum phenomena. For their part, the group plans to use the technique to manipulate atoms into configurations that could generate the first purely magnetic quantum gate — a key building block for a new type of quantum computer.</p>
<p>The team has <a href="https://www.science.org/doi/10.1126/science.adh3023" target="_blank" rel="noopener">published their results today</a> in the journal <em>Science</em>. The study’s co-authors include lead author and physics graduate student Li Du, along with Pierre Barral, Michael Cantara, Julius de Hond, and Yu-Kun Lu — all members of the MIT-Harvard Center for Ultracold Atoms, the Department of Physics, and the Research Laboratory of Electronics at MIT.</p>
<p><strong>Peaks and valleys</strong></p>
<p>To manipulate and arrange atoms, physicists typically first cool a cloud of atoms to temperatures approaching absolute zero, then use a system of laser beams to corral the atoms into an optical trap.</p>
<p>Laser light is an electromagnetic wave with a specific wavelength (the distance between maxima of the electric field) and frequency. The wavelength limits the smallest pattern into which light can be shaped to typically 500 nanometers, the so-called optical resolution limit. Since atoms are attracted by laser light of certain frequencies, atoms will be positioned at the points of peak laser intensity. For this reason, existing techniques have been limited in how close they can position atomic particles, and could not be used to explore phenomena that happen at much shorter distances.</p>
<p>“Conventional techniques stop at 500 nanometers, limited not by the atoms but by the wavelength of light,” Ketterle explains. “We have found now a new trick with light where we can break through that limit.”</p>
<p>The team’s new approach, like current techniques, starts by cooling a cloud of atoms — in this case, to about 1 microkelvin, just a hair above absolute zero — at which point, the atoms come to a near-standstill. Physicists can then use lasers to move the frozen particles into desired configurations.</p>
<p>Then, Du and his collaborators worked with two laser beams, each with a different frequency, or color, and circular polarization, or direction of the laser’s electric field. When the two beams travel through a super-cooled cloud of atoms, the atoms can orient their spin in opposite directions, following either of the two lasers’ polarization. The result is that the beams produce two groups of the same atoms, only with opposite spins.</p>
<p>Each laser beam formed a standing wave, a periodic pattern of electric field intensity with a spatial period of 500 nanometers. Due to their different polarizations, each standing wave attracted and corralled one of two groups of atoms, depending on their spin. The lasers could be overlaid and tuned such that the distance between their respective peaks is as small as 50 nanometers, meaning that the atoms gravitating to each respective laser’s peaks would be separated by the same 50 nanometers.</p>
<p>But in order for this to happen, the lasers would have to be extremely stable and immune to all external noise, such as from shaking or even breathing on the experiment. The team realized they could stabilize both lasers by directing them through an optical fiber, which served to lock the light beams in place in relation to each other.</p>
<p>“The idea of sending both beams through the optical fiber meant the whole machine could shake violently, but the two laser beams stayed absolutely stable with respect to each others,” Du says.</p>
<p><strong>Magnetic forces at close range</strong></p>
<p>As a first test of their new technique, the team used atoms of dysprosium — a rare-earth metal that is one of the strongest magnetic elements in the periodic table, particularly at ultracold temperatures. However, at the scale of atoms, the element’s magnetic interactions are relatively weak at distances of even 500 nanometers. As with common refrigerator magnets, the magnetic attraction between atoms increases with proximity, and the scientists suspected that if their new technique could space dysprosium atoms as close as 50 nanometers apart, they might observe the emergence of otherwise weak interactions between the magnetic atoms.</p>
<p>“We could suddenly have magnetic interactions, which used to be almost neglible but now are really strong,” Ketterle says.</p>
<p>The team applied their technique to dysprosium, first super-cooling the atoms, then passing two lasers through to split the atoms into two spin groups, or layers. They then directed the lasers through an optical fiber to stabilize them, and found that indeed, the two layers of dysprosium atoms gravitated to their respective laser peaks, which in effect separated the layers of atoms by 50 nanometers — the closest distance that any ultracold atom experiment has been able to achieve.</p>
<p>At this extremely close proximity, the atoms’ natural magnetic interactions were significantly enhanced, and were 1,000 times stronger than if they were positioned 500 nanometers apart. The team observed that these interactions resulted in two novel quantum phenomena: collective oscillation, in which one layer’s vibrations caused the other layer to vibrate in sync; and thermalization, in which one layer transferred heat to the other, purely through magnetic fluctuations in the atoms.</p>
<p>“Until now, heat between atoms could only by exchanged when they were in the same physical space and could collide,” Du notes. “Now we have seen atomic layers, separated by vacuum, and they exchange heat via fluctuating magnetic fields.”</p>
<p>The team’s results introduce a new technique that can be used to position many types of atom in close proximity. They also show that atoms, placed close enough together, can exhibit interesting quantum phenomena, that could be harnessed to build new quantum materials, and potentially, magnetically-driven atomic systems for quantum computers.</p>
<p>“We are really bringing super-resolution methods to the field, and it will become a general tool for doing quantum simulations,” Ketterle says. “There are many variants possible, which we are working on.”</p>
<p>This research was funded, in part, by the National Science Foundation and the Department of Defense.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Natural language boosts LLM performance in coding, planning, and robotics</title>
		<link>https://www.sawberries.com/2024/05/02/natural-language-boosts-llm-performance-coding-planning-robotics-0501/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 02 May 2024 07:25:27 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Brain and cognitive sciences]]></category>
		<category><![CDATA[Center for Brains Minds and Machines]]></category>
		<category><![CDATA[Computer Science and Artificial Intelligence Laboratory (CSAIL)]]></category>
		<category><![CDATA[Computer science and technology]]></category>
		<category><![CDATA[Computer vision]]></category>
		<category><![CDATA[Defense Advanced Research Projects Agency (DARPA)]]></category>
		<category><![CDATA[Department of Defense (DoD)]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Human-computer interaction]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT-IBM Watson AI Lab]]></category>
		<category><![CDATA[National Science Foundation (NSF)]]></category>
		<category><![CDATA[Natural language processing]]></category>
		<category><![CDATA[Programming]]></category>
		<category><![CDATA[programming languages]]></category>
		<category><![CDATA[Quest for Intelligence]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<category><![CDATA[School of Science]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/05/02/natural-language-boosts-llm-performance-coding-planning-robotics-0501/</guid>

					<description><![CDATA[Large language models (LLMs) are becoming increasingly useful for programming and robotics tasks, but for more complicated reasoning problems, the gap between these systems and humans looms large. Without the ability to learn new concepts like humans do, these systems fail to form good abstractions — essentially, high-level representations of complex concepts that skip less-important [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Large language models (LLMs) are becoming increasingly useful for programming and robotics tasks, but for more complicated reasoning problems, the gap between these systems and humans looms large. Without the ability to learn new concepts like humans do, these systems fail to form good abstractions — essentially, high-level representations of complex concepts that skip less-important details — and thus sputter when asked to do more sophisticated tasks.</p>
<p>Luckily, MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) researchers have found a treasure trove of abstractions within natural language. In three papers to be presented at the International Conference on Learning Representations this month, the group shows how our everyday words are a rich source of context for language models, helping them build better overarching representations for code synthesis, AI planning, and robotic navigation and manipulation.</p>
<p>The three separate frameworks build libraries of abstractions for their given task: <a href="https://arxiv.org/abs/2310.19791" target="_blank" rel="noopener">LILO</a> (library induction from language observations) can synthesize, compress, and document code; <a href="https://arxiv.org/abs/2312.08566" target="_blank" rel="noopener">Ada</a> (action domain acquisition) explores sequential decision-making for artificial intelligence agents; and <a href="https://arxiv.org/abs/2402.18759" target="_blank" rel="noopener">LGA</a> (language-guided abstraction) helps robots better understand their environments to develop more feasible plans. Each system is a neurosymbolic method, a type of AI that blends human-like neural networks and program-like logical components.</p>
<p><strong>LILO: A neurosymbolic framework that codes</strong></p>
<p>Large language models can be used to quickly write solutions to small-scale coding tasks, but cannot yet architect entire software libraries like the ones written by human software engineers. To take their software development capabilities further, AI models need to refactor (cut down and combine) code into libraries of succinct, readable, and reusable programs.</p>
<p>Refactoring tools like the previously developed MIT-led <a href="https://mlb2251.github.io/stitch_jul11.pdf" target="_blank" rel="noopener">Stitch</a> algorithm can automatically identify abstractions, so, in a nod to the Disney movie “Lilo &amp; Stitch,” CSAIL researchers combined these algorithmic refactoring approaches with LLMs. Their neurosymbolic method LILO uses a standard LLM to write code, then pairs it with Stitch to find abstractions that are comprehensively documented in a library.</p>
<p>LILO’s unique emphasis on natural language allows the system to do tasks that require human-like commonsense knowledge, such as identifying and removing all vowels from a string of code and drawing a snowflake. In both cases, the CSAIL system outperformed standalone LLMs, as well as a previous library learning algorithm from MIT called DreamCoder, indicating its ability to build a deeper understanding of the words within prompts. These encouraging results point to how LILO could assist with things like writing programs to manipulate documents like Excel spreadsheets, helping AI answer questions about visuals, and drawing 2D graphics.</p>
<p>“Language models prefer to work with functions that are named in natural language,” says Gabe Grand SM &#8217;23, an MIT PhD student in electrical engineering and computer science, CSAIL affiliate, and lead author on the research. “Our work creates more straightforward abstractions for language models and assigns natural language names and documentation to each one, leading to more interpretable code for programmers and improved system performance.”</p>
<p>When prompted on a programming task, LILO first uses an LLM to quickly propose solutions based on data it was trained on, and then the system slowly searches more exhaustively for outside solutions. Next, Stitch efficiently identifies common structures within the code and pulls out useful abstractions. These are then automatically named and documented by LILO, resulting in simplified programs that can be used by the system to solve more complex tasks.</p>
<p>The MIT framework writes programs in domain-specific programming languages, like Logo, a language developed at MIT in the 1970s to teach children about programming. Scaling up automated refactoring algorithms to handle more general programming languages like Python will be a focus for future research. Still, their work represents a step forward for how language models can facilitate increasingly elaborate coding activities.</p>
<p><strong>Ada: Natural language guides AI task planning</strong></p>
<p>Just like in programming, AI models that automate multi-step tasks in households and command-based video games lack abstractions. Imagine you’re cooking breakfast and ask your roommate to bring a hot egg to the table — they’ll intuitively abstract their background knowledge about cooking in your kitchen into a sequence of actions. In contrast, an LLM trained on similar information will still struggle to reason about what they need to build a flexible plan.</p>
<p>Named after the famed mathematician Ada Lovelace, who many consider the world’s first programmer, the CSAIL-led “Ada” framework makes headway on this issue by developing libraries of useful plans for virtual kitchen chores and gaming. The method trains on potential tasks and their natural language descriptions, then a language model proposes action abstractions from this dataset. A human operator scores and filters the best plans into a library, so that the best possible actions can be implemented into hierarchical plans for different tasks.</p>
<p>“Traditionally, large language models have struggled with more complex tasks because of problems like reasoning about abstractions,” says Ada lead researcher Lio Wong, an MIT graduate student in brain and cognitive sciences, CSAIL affiliate, and LILO coauthor. “But we can combine the tools that software engineers and roboticists use with LLMs to solve hard problems, such as decision-making in virtual environments.”</p>
<p>When the researchers incorporated the widely-used large language model GPT-4 into Ada, the system completed more tasks in a kitchen simulator and Mini Minecraft than the AI decision-making baseline “Code as Policies.” Ada used the background information hidden within natural language to understand how to place chilled wine in a cabinet and craft a bed. The results indicated a staggering 59 and 89 percent task accuracy improvement, respectively.</p>
<p>With this success, the researchers hope to generalize their work to real-world homes, with the hopes that Ada could assist with other household tasks and aid multiple robots in a kitchen. For now, its key limitation is that it uses a generic LLM, so the CSAIL team wants to apply a more powerful, fine-tuned language model that could assist with more extensive planning. Wong and her colleagues are also considering combining Ada with a robotic manipulation framework fresh out of CSAIL: LGA (language-guided abstraction).</p>
<p><strong>Language-guided abstraction: Representations for robotic tasks</strong></p>
<p>Andi Peng SM ’23, an MIT graduate student in electrical engineering and computer science and CSAIL affiliate, and her coauthors designed a method to help machines interpret their surroundings more like humans, cutting out unnecessary details in a complex environment like a factory or kitchen. Just like LILO and Ada, LGA has a novel focus on how natural language leads us to those better abstractions.</p>
<p>In these more unstructured environments, a robot will need some common sense about what it’s tasked with, even with basic training beforehand. Ask a robot to hand you a bowl, for instance, and the machine will need a general understanding of which features are important within its surroundings. From there, it can reason about how to give you the item you want. </p>
<p>In LGA’s case, humans first provide a pre-trained language model with a general task description using natural language, like “bring me my hat.” Then, the model translates this information into abstractions about the essential elements needed to perform this task. Finally, an imitation policy trained on a few demonstrations can implement these abstractions to guide a robot to grab the desired item.</p>
<p>Previous work required a person to take extensive notes on different manipulation tasks to pre-train a robot, which can be expensive. Remarkably, LGA guides language models to produce abstractions similar to those of a human annotator, but in less time. To illustrate this, LGA developed robotic policies to help Boston Dynamics’ Spot quadruped pick up fruits and throw drinks in a recycling bin. These experiments show how the MIT-developed method can scan the world and develop effective plans in unstructured environments, potentially guiding autonomous vehicles on the road and robots working in factories and kitchens.</p>
<p>“In robotics, a truth we often disregard is how much we need to refine our data to make a robot useful in the real world,” says Peng. “Beyond simply memorizing what’s in an image for training robots to perform tasks, we wanted to leverage computer vision and captioning models in conjunction with language. By producing text captions from what a robot sees, we show that language models can essentially build important world knowledge for a robot.”</p>
<p>The challenge for LGA is that some behaviors can’t be explained in language, making certain tasks underspecified. To expand how they represent features in an environment, Peng and her colleagues are considering incorporating multimodal visualization interfaces into their work. In the meantime, LGA provides a way for robots to gain a better feel for their surroundings when giving humans a helping hand. </p>
<p><strong>An “exciting frontier” in AI</strong></p>
<p>“Library learning represents one of the most exciting frontiers in artificial intelligence, offering a path towards discovering and reasoning over compositional abstractions,” says assistant professor at the University of Wisconsin-Madison Robert Hawkins, who was not involved with the papers. Hawkins notes that previous techniques exploring this subject have been “too computationally expensive to use at scale” and have an issue with the lambdas, or keywords used to describe new functions in many languages, that they generate. “They tend to produce opaque &#8216;lambda salads,&#8217; big piles of hard-to-interpret functions. These recent papers demonstrate a compelling way forward by placing large language models in an interactive loop with symbolic search, compression, and planning algorithms. This work enables the rapid acquisition of more interpretable and adaptive libraries for the task at hand.”</p>
<p>By building libraries of high-quality code abstractions using natural language, the three neurosymbolic methods make it easier for language models to tackle more elaborate problems and environments in the future. This deeper understanding of the precise keywords within a prompt presents a path forward in developing more human-like AI models.</p>
<p>MIT CSAIL members are senior authors for each paper: Joshua Tenenbaum, a professor of brain and cognitive sciences, for both LILO and Ada; Julie Shah, head of the Department of Aeronautics and Astronautics, for LGA; and Jacob Andreas, associate professor of electrical engineering and computer science, for all three. The additional MIT authors are all PhD students: Maddy Bowers and Theo X. Olausson for LILO, Jiayuan Mao and Pratyusha Sharma for Ada, and Belinda Z. Li for LGA. Muxin Liu of Harvey Mudd College was a coauthor on LILO; Zachary Siegel of Princeton University, Jaihai Feng of the University of California at Berkeley, and Noa Korneev of Microsoft were coauthors on Ada; and Ilia Sucholutsky, Theodore R. Sumers, and Thomas L. Griffiths of Princeton were coauthors on LGA. </p>
<p>LILO and Ada were supported, in part, by ​​MIT Quest for Intelligence, the MIT-IBM Watson AI Lab, Intel, U.S. Air Force Office of Scientific Research, the U.S. Defense Advanced Research Projects Agency, and the U.S. Office of Naval Research, with the latter project also receiving funding from the Center for Brains, Minds and Machines. LGA received funding from the U.S. National Science Foundation, Open Philanthropy, the Natural Sciences and Engineering Research Council of Canada, and the U.S. Department of Defense.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>MIT faculty, instructors, students experiment with generative AI in teaching and learning</title>
		<link>https://www.sawberries.com/2024/04/29/mit-faculty-instructors-students-experiment-generative-ai-teaching-learning-0429/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Mon, 29 Apr 2024 18:01:37 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Classes and programs]]></category>
		<category><![CDATA[Education, teaching, academics]]></category>
		<category><![CDATA[Electrical Engineering & Computer Science (eecs)]]></category>
		<category><![CDATA[Faculty]]></category>
		<category><![CDATA[Human-computer interaction]]></category>
		<category><![CDATA[Innovation and Entrepreneurship (I&E)]]></category>
		<category><![CDATA[Internet]]></category>
		<category><![CDATA[K-12 education]]></category>
		<category><![CDATA[Labor and jobs]]></category>
		<category><![CDATA[Languages]]></category>
		<category><![CDATA[Learning]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[MIT Schwarzman College of Computing]]></category>
		<category><![CDATA[MIT Sloan School of Management]]></category>
		<category><![CDATA[MITx]]></category>
		<category><![CDATA[Office of Open Learning]]></category>
		<category><![CDATA[Online learning]]></category>
		<category><![CDATA[School of Engineering]]></category>
		<category><![CDATA[School of Humanities Arts and Social Sciences]]></category>
		<category><![CDATA[School of Science]]></category>
		<category><![CDATA[Special events and guest speakers]]></category>
		<category><![CDATA[Staff]]></category>
		<category><![CDATA[Students]]></category>
		<category><![CDATA[Technology and society]]></category>
		<category><![CDATA[Vice Chancellor]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/29/mit-faculty-instructors-students-experiment-generative-ai-teaching-learning-0429/</guid>

					<description><![CDATA[How can MIT’s community leverage generative AI to support learning and work on campus and beyond? At MIT’s Festival of Learning 2024, faculty and instructors, students, staff, and alumni exchanged perspectives about the digital tools and innovations they’re experimenting with in the classroom. Panelists agreed that generative AI should be used to scaffold — not [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>How can MIT’s community leverage generative AI to support learning and work on campus and beyond?</p>
<p>At MIT’s Festival of Learning 2024, faculty and instructors, students, staff, and alumni exchanged perspectives about the digital tools and innovations they’re experimenting with in the classroom. Panelists agreed that generative AI should be used to scaffold — not replace — learning experiences.</p>
<p>This annual event, co-sponsored by MIT Open Learning and the Office of the Vice Chancellor, celebrates teaching and learning innovations. When introducing new teaching and learning technologies, panelists stressed the importance of iteration and teaching students how to develop critical thinking skills while leveraging technologies like generative AI.</p>
<p>“The Festival of Learning brings the MIT community together to explore and celebrate what we do every day in the classroom,” said Christopher Capozzola, senior associate dean for open learning. “This year&#8217;s deep dive into generative AI was reflective and practical — yet another remarkable instance of ‘mind and hand’ here at the Institute.” <strong> </strong></p>
<p><strong>Incorporating generative AI into learning experiences </strong></p>
<p>MIT faculty and instructors aren’t just willing to experiment with generative AI — some believe it’s a necessary tool to prepare students to be competitive in the workforce. “In a future state, we will know how to teach skills with generative AI, but we need to be making iterative steps to get there instead of waiting around,” said Melissa Webster, lecturer in managerial communication at MIT Sloan School of Management. </p>
<p>Some educators are revisiting their courses’ learning goals and redesigning assignments so students can achieve the desired outcomes in a world with AI. Webster, for example, previously paired written and oral assignments so students would develop ways of thinking. But, she saw an opportunity for teaching experimentation with generative AI. If students are using tools such as ChatGPT to help produce writing, Webster asked, “how do we still get the thinking part in there?”</p>
<p>One of the new assignments Webster developed asked students to generate cover letters through ChatGPT and critique the results from the perspective of future hiring managers. Beyond learning how to refine generative AI prompts to produce better outputs, Webster shared that “students are thinking more about their thinking.” Reviewing their ChatGPT-generated cover letter helped students determine what to say and how to say it, supporting their development of higher-level strategic skills like persuasion and understanding audiences.</p>
<p>Takako Aikawa, senior lecturer at the MIT Global Studies and Languages Section, redesigned a vocabulary exercise to ensure students developed a deeper understanding of the Japanese language, rather than just right or wrong answers. Students compared short sentences written by themselves and by ChatGPT and developed broader vocabulary and grammar patterns beyond the textbook. “This type of activity enhances not only their linguistic skills but stimulates their metacognitive or analytical thinking,” said Aikawa. “They have to think in Japanese for these exercises.”</p>
<p>While these panelists and other Institute faculty and instructors are redesigning their assignments, many MIT undergraduate and graduate students across different academic departments are leveraging generative AI for efficiency: creating presentations, summarizing notes, and quickly retrieving specific ideas from long documents. But this technology can also creatively personalize learning experiences. Its ability to communicate information in different ways allows students with different backgrounds and abilities to adapt course material in a way that’s specific to their particular context. </p>
<p>Generative AI, for example, can help with student-centered learning at the K-12 level. Joe Diaz, program manager and STEAM educator for MIT pK-12 at Open Learning, encouraged educators to foster learning experiences where the student can take ownership. “Take something that kids care about and they’re passionate about, and they can discern where [generative AI] might not be correct or trustworthy,” said Diaz.</p>
<p>Panelists encouraged educators to think about generative AI in ways that move beyond a course policy statement. When incorporating generative AI into assignments, the key is to be clear about learning goals and open to sharing examples of how generative AI could be used in ways that align with those goals. </p>
<p><strong>The importance of critical thinking</strong></p>
<p>Although generative AI can have positive impacts on educational experiences, users need to understand why large language models might produce incorrect or biased results. Faculty, instructors, and student panelists emphasized that it’s critical to contextualize how generative AI works. “[Instructors] try to explain what goes on in the back end and that really does help my understanding when reading the answers that I’m getting from ChatGPT or Copilot,” said Joyce Yuan, a senior in computer science. </p>
<p>Jesse Thaler, professor of physics and director of the National Science Foundation Institute for Artificial Intelligence and Fundamental Interactions, warned about trusting a probabilistic tool to give definitive answers without uncertainty bands. “The interface and the output needs to be of a form that there are these pieces that you can verify or things that you can cross-check,” Thaler said.</p>
<p>When introducing tools like calculators or generative AI, the faculty and instructors on the panel said it’s essential for students to develop critical thinking skills in those particular academic and professional contexts. Computer science courses, for example, could permit students to use ChatGPT for help with their homework if the problem sets are broad enough that generative AI tools wouldn’t capture the full answer. However, introductory students who haven’t developed the understanding of programming concepts need to be able to discern whether the information ChatGPT generated was accurate or not.</p>
<p>Ana Bell, senior lecturer of the Department of Electrical Engineering and Computer Science and <em>MITx </em>digital learning scientist, dedicated one class toward the end of the semester of Course 6.100L (Introduction to Computer Science and Programming Using Python) to teach students how to use ChatGPT for programming questions. She wanted students to understand why setting up generative AI tools with the context for programming problems, inputting as many details as possible, will help achieve the best possible results. “Even after it gives you a response back, you have to be critical about that response,” said Bell. By waiting to introduce ChatGPT until this stage, students were able to look at generative AI’s answers critically because they had spent the semester developing the skills to be able to identify whether problem sets were incorrect or might not work for every case. </p>
<p><strong>A scaffold for learning experiences</strong></p>
<p>The bottom line from the panelists during the Festival of Learning was that generative AI should provide scaffolding for engaging learning experiences where students can still achieve desired learning goals. The MIT undergraduate and graduate student panelists found it invaluable when educators set expectations for the course about when and how it’s appropriate to use AI tools. Informing students of the learning goals allows them to understand whether generative AI will help or hinder their learning. Student panelists asked for trust that they would use generative AI as a starting point, or treat it like a brainstorming session with a friend for a group project. Faculty and instructor panelists said they will continue iterating their lesson plans to best support student learning and critical thinking. </p>
<p>Panelists from both sides of the classroom discussed the importance of generative AI users being responsible for the content they produce and avoiding automation bias — trusting the technology’s response implicitly without thinking critically about why it produced that answer and whether it’s accurate. But since generative AI is built by people making design decisions, Thaler told students, “You have power to change the behavior of those tools.”</p>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Seven from MIT elected to American Academy of Arts and Sciences for 2024</title>
		<link>https://www.sawberries.com/2024/04/25/seven-mit-elected-american-academy-arts-and-sciences-0425/</link>
		
		<dc:creator><![CDATA[ross]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 14:14:54 +0000</pubDate>
				<category><![CDATA[Aeronautical and astronautical engineering]]></category>
		<category><![CDATA[Awards, honors and fellowships]]></category>
		<category><![CDATA[Chemistry]]></category>
		<category><![CDATA[economics]]></category>
		<category><![CDATA[Faculty]]></category>
		<category><![CDATA[Mathematics]]></category>
		<category><![CDATA[Media Lab]]></category>
		<category><![CDATA[Physics]]></category>
		<category><![CDATA[School of Architecture and Planning]]></category>
		<category><![CDATA[School of Humanities Arts and Social Sciences]]></category>
		<category><![CDATA[School of Science]]></category>
		<guid isPermaLink="false">https://www.sawberries.com/2024/04/25/seven-mit-elected-american-academy-arts-and-sciences-0425/</guid>

					<description><![CDATA[Eight MIT faculty members are among the 250 leaders from academia, the arts, industry, public policy, and research elected to the American Academy of Arts and Sciences, the academy announced April 24. One of the nation’s most prestigious honorary societies, the academy is also a leading center for independent policy research. Members contribute to academy [&#8230;]]]></description>
										<content:encoded><![CDATA[<div>
<p>Eight MIT faculty members are among the 250 leaders from academia, the arts, industry, public policy, and research elected to the American Academy of Arts and Sciences, the academy announced April 24.</p>
</p>
<p>One of the nation’s most prestigious honorary societies, the academy is also a leading center for independent policy research. Members contribute to academy publications, as well as studies of science and technology policy, energy and global security, social policy and American institutions, the humanities and culture, and education.</p>
</p>
<p>Those elected from MIT in 2024 are:</p>
</p>
<ul>
<li>Edward F. Crawley, professor of aeronautics and astronautics, post-tenure;</li>
<li>Nathaniel Hendren, professor of economics;</li>
<li>Mei Hong, David A. Leighty Professor of Chemistry;</li>
<li>Tod Machover, Muriel R. Cooper Professor of Interactive Media Design;</li>
<li>Anna Mikusheva, professor of economics;</li>
<li>Elchanan Mossel, professor of mathematics; and</li>
<li>Xiao-Gang Wen, Cecil and Ida Green Professor of Physics.</li>
</ul>
<p>“We honor these artists, scholars, scientists, and leaders in the public, non-profit, and private sectors for their accomplishments and for the curiosity, creativity, and courage required to reach new heights,” says David Oxtoby, president of the academy. “We invite these exceptional individuals to join in the academy’s work to address serious challenges and advance the common good.”</p>
</p>
<p>Since its founding in 1780, the academy has elected leading thinkers from each generation, including George Washington and Benjamin Franklin in the 18th century, Maria Mitchell and Daniel Webster in the 19th century, and Toni Morrison and Albert Einstein in the 20th century. The current membership includes more than 250 Nobel and Pulitzer Prize winners.</p>
</div>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
